  145  find $PWD -type f -name “*.txt”
  146  find 'CS131' -type f -name “*.txt”
  147  find '/mnt/scratch/hyeyeon/CS131' -type f -name “*.txt”
  148  vi verified1.txt
  149  cd ..
  150  cd mnt
  151  cd scratch
  152  cd hyeyeon
  153  cd CS131
  154  ls -atlr
  155  sed -n'/Y/p' verified1.txt
  156  head verified1.txt
  157  sed -n'/stern/p' verified1.txt
  158  sed -n'\stern\p' verified1.txt
  159  sed -n'/stern/p' verified1.txt
  160  sed -n '/stern/p' verified1.txt
  161  vi *.txt
  162  ls -atlr
  163  vi .unverified1.txt.swp 
  164  rm .unverified1.txt.swp 
  165  ls -atlr
  166  cd ..
  167  cd mnt
  168  cd scratch
  169  cd hyeyeon
  170  cd CS131
  171  ls -atlr
  172  vi test.txt
  173  sed 's/|/,/g' tes.txt
  174  sed 's/,/|/g' emp.lst
  175  sed 's/,/|/g' test.txt
  176  sed 's/|/,/g' test.txt
  177  cat test.txt
  178  $ echo 'The special character $VAR echo hello and | ls chap*'
  179  #!/bin/bash
  180  $ echo 'The special character $VAR echo hello and | ls chap*'
  181  echo 'The special character $VAR echo hello and | ls chap*'
  182  sed '3q' test.txt
  183  head -n3 test.txt
  184  vi test.txt
  185  sed 's/ *|/|/g' test.txt
  186  cat test.txt
  187  vi test.txt
  188  sed 's/ *|/|/g' test.txt
  189  cat test.txt
  190  vi test.txt
  191  sed 's/ *|/|/g' test.txt
  192  cat test.txt
  193  #!/bin/bash
  194  number=2
  195   while [ $number -gt 0 ];   do        echo "$number";       number=`expr $number - 1`;              done
  196  number=2
  197  while[$number -gt 0]
  198  #!/bin/bash
  199  number=2
  200  while [ $number -gt 0 ]; do echo "$number"; number = 'expr $number -1'; done
  201  #!/bin/bash
  202  while [ $number -gt 0 ]; do echo "$number"; number = 'expr $number -1'; done
  203  #!/bin/bash
  204  while [ $number -gt 0 ]; do echo "$number"; number = 'expr $number -1'; done
  205  ls v[1-5]*
  206  ls v*
  207  ls v[1]*
  208  vi verified2.txt
  209  ls v[1-2]*
  210  ls v*[1-2]
  211  ls a?1-5
  212  ls a?1-2
  213  ls *v*[1-2]*
  214  ls v*[1-2]
  215  ls v?[1-2]
  216  ls v?1-2
  217  ls v*[1-2]
  218  vi v3.txt
  219  vi v4.txt
  220  vi v5.txt
  221  ls v*[1-5]
  222  ls ?v?1?5
  223  ls v?1-5
  224  ls *v*[1,5]*
  225  ls v*
  226  ls v
  227  ls v*[1-5]
  228  ls v*[1,5]
  229  ls v[1-5]*
  230  #!/bin/bash
  231  for number in 10 11 5; do echo -n "$number"; done
  232  #!/bin/bash
  233  number = 2
  234  until [$number -eq 0]; do echo -n "$number"; number = 'expr $number -1'; done
  235  #!/bin/bash
  236  number = 2
  237  until [$number -eq 0]; do echo -n "$number"; number = 'expr $number - 1'; done
  238  #!/bin/bash
  239  number = 2
  240  #!/bin/bash
  241  number = 2
  242  #!/bin/bash
  243  $number =2
  244  #!/bin/bash
  245  number = 2
  246  #!/bin/bash
  247  number=2
  248  until [ $number -eq 0]; do echo -n "$number"; number = 'expr $number -1 '; done
  249  #!/bin/bash
  250  number =2
  251  number=2
  252  if [ $sumber -eq 3]; then echo "Hi!"; else echo "Bye!"; fi
  253  #!/bin/bash
  254  number=2
  255  if [ $number -eq 3]; then echo "Hi!"; else echo "Bye!"; fi
  256  ls v[1-5]*
  257  ls v*[1-5]
  258  ls -atlr
  259  ls v*
  260  ls ls?v?1?5
  261  #!/bin/bash
  262  number=2
  263  ls v*
  264  ls v*[1-2]
  265  ls v*[3-5]
  266  ls v[1-5]*
  267  ls v?1-5
  268  ls v?
  269  cat test.txt
  270  #!/bin/bash
  271  read What a wonderful day!
  272  What a wonderful day!
  273  #!/bin/bash
  274  What a wonderful day!
  275  #!/bin/bash
  276  read What a wonderful day!
  277  echo z y x
  278  cd ..
  279  cd mnt
  280  cd scratch
  281  cd hyeyeon
  282  cd CS131
  283  ls -atlr
  284  head amazon.tsv
  285  echo $(($RANDOM % 99)+1)
  286  echo $(($RANDOM % 99))
  287  echo $(($RANDOM % 99)+1))
  288  echo $(($RANDOM % 99)+1)
  289  echo $(($RANDOM % 100)
  290  )
  291  echo $(($RANDOM % 100))
  292      // 0~99
  293  awk "NR >= 1 && NR <=100" amazon_reviews_us_Books_v1_02.tsv|cut -f2 > test.tsv
  294  head test.tsv
  295  10
  296  (($RANDOM % 100))+1
  297  $ echo $(($RANDOM % 99))+1 
  298  echo $(($RANDOM % 99))+1
  299  $
  300  echo $((($RANDOM % 99))+1)
  301  echo $(($RANDOM % 99) +$1)
  302  echo $(($RANDOM % 99))+$1echo $(($RANDOM % 99))+$1
  303  echo $(($RANDOM % 99))+$1
  304  echo $(($RANDOM % 99))+$1)
  305  echo $(($RANDOM % 99)) $1)
  306  echo $(($RANDOM % 99)) $1
  307  echo $((($RANDOM % 99)) + $1)
  308  echo $(($RANDOM % 99))
  309  echo $RANDOM+$1
  310  echo $RANDOM+1
  311  echo $(RANDOM+1)
  312  tmux attach -t homework
  313  awk "NR>=$1&&NR<=$100" amazon_reviews_us_Books_v1_02.tsv > amazon.tsv
  314  awk "NR>=1&&NR<=100" amazon_reviews_us_Books_v1_02.tsv > amazon.tsv
  315  cut -f8 amazon.tsv > star_rating.tsv
  316  head star_rating.tsv 
  317  vi randomsample.sh
  318  ./randomsample.sh
  319  chmod 755 randomsample.sh
  320  ./randomsample.sh
  321  history>cmds.log
  322  tail cmds.log
  323  tmux new-session -s homework
  324  cd ..
  325  cd mnt
  326  cd scratch
  327  cd hyeyeon
  328  cd CS131
  329  ls -atlr
  330  ./test.sh
  331  chmod 755 test.sh
  332  sh test.sh
  333  chmod 755 test.sh
  334  vi test.sh
  335  chmod 755 test.sh
  336  ./test.sh
  337  vi test.sh
  338  ./test.sh
  339  #!/bin/bash
  340  x=(($RANDOM % 100))
  341  x=($RANDOM % 100)
  342  s=($RANDOM % 100)
  343  if s>(100-x); do
  344  if s>(100-x); then while s<=(100-x)
  345  while s<=100-x; do s=($RANDOM % 100); done
  346  n=100-x
  347  echo n
  348  echo $n
  349  n=$(100-x)
  350  let n = 100-x
  351  echo $x
  352  echo $(($RANDOM % 100))
  353  x=$(($RANDOM % 100))
  354  echo $x
  355  echo $((100-x))
  356  s=s=$(($RANDOM % 100)) 
  357  s=$(($RANDOM % 100)) 
  358  let e=s+x
  359  echo $e
  360  echo $s
  361  e=$((s+x))
  362  echo $e
  363  if s>$((100-x)); then while s<=$((100-x)); do s=$(($RANDOM % 100)) ; done; e=$((s+x)); sed -n '$s,$ep' test.tsv; fi
  364  echo $s
  365  echo $e
  366  grep -n'{$s}' test.tsv
  367  grep -n{$s} test.tsv
  368  grep -n'{$s}' test.tsv
  369  grep -n'$s' test.tsv
  370  grep -n"{$s}" test.tsv
  371  echo $s
  372  sed -n '{$s},{$e}p' amazon.tsv
  373  sed -n '{$s,$e}p' amazon.tsv
  374  sed -n "{$s,$e}p" test.tsv
  375  sed -n "{$s}p" test.tsv
  376  sed -n '"{$s}"p' test.tsv
  377  sed -n '{$s}p' test.tsv
  378  sed -n '$sp' test.tsv
  379  sed -n "$sp" test.tsv
  380  grep -n "s" test.tsv
  381  sed -n '"s"p' test.tsv
  382  sed -n '{$s}p' test.tsv
  383  sed -n '{$x}p' test.tsv
  384  echo $x
  385  sed -n '9p' test.tsv
  386  grep -n "x" test.tsv
  387  sed -n '"$x"p' test.tsv
  388  sed -n '{$x}p' test.tsv
  389  awk "NR>={$s}&&NR<={$e}" test.tsv
  390  awk "NR>=$s&&NR<=$e" test.tsv
  391  vi test.sh
  392  ./test.sh
  393  vi test.sh
  394  ./test.sh
  395  vi test.sh
  396  ./test.sh
  397  vi test.sh
  398  ./test.sh
  399  vi test.sh
  400  ./test.sh
  401  vi test.sh
  402  ./test.sh
  403  echo $x
  404  echo $((100-x))
  405  vi test.sh
  406  cut -f1 amazon.tsv | head
  407  head amazon.tsv
  408  cut -7 amazon.tsv|head
  409  cut -f7 amazon.tsv|head
  410  cut -f8 amazon.tsv|head
  411  ls -atlr
  412  rm test.sh
  413  rm test.tsv
  414  rm amazon.tsv
  415  script ws9.txt
  416  vi ws9.txt
  417  git init
  418  git branch
  419  git checkout -b ws9
  420  git branch
  421  git add ws9.txt
  422  git add cmds.log
  423  git status
  424  git commit -m "ws9"
  425  git push -u origin ws9
  426  cd ..
  427  cd mnt
  428  cd scratch
  429  cd hyeyeon
  430  cd CS131
  431  cp "/home/hyeyeon/CS131/downloaded_tweets_extend_nolf2.tsv" /mnt/scratch/hyeyeon/CS131
  432  cp "/home/hyeyeon/CS131/downloaded_tweets_extend_original_nolf2.tsv" mnt/scratch/hyeyeon/CS131
  433  ls -atlr
  434  cp "/home/hyeyeon/CS131/downloaded_tweets_extend_original_nolf2.tsv" /mnt/scratch/hyeyeon/CS131
  435  ls 
  436  /mnt/scratch/hyeyeon/CS131
  437  ls
  438  pwd
  439  cd ..
  440  /mnt/scratch/hyeyeon/CS131
  441  cd /mnt/scratch/hyeyeon/CS131
  442  ls -atlr
  443  cd /mnt/scratch/hyeyeon/CS131
  444  ls
  445  vi a.txt
  446  vi b.txt
  447  dd
  448  #!/usr/bin/perl
  449  print a.txt . b.txt;
  450  "a.txt" . "b.txt";
  451  /mnt/scratch/hyeyeon/CS131
  452  cd ..
  453  /mnt/scratch/hyeyeon/CS131
  454  cd /mnt/scratch/hyeyeon/CS131
  455  ls
  456  ls -atlr
  457  head downloaded_tweets_extend_nolf2.tsv
  458  cut -f5 downloaded_tweets_extend_original_nolf2.tsv | head
  459  cut -f5 downloaded_tweets_extend_original_nolf2.tsv
  460  cd /mnt/scratch/hyeyeon/CS131
  461  ls
  462  perl -p -i -e '$.==<22:$2> and print "<cat b.txt>"' a.txt
  463  head a.txt
  464  head b.txt
  465  awk -F'\t' '{print $1}' a.txt | awk -F'\t' '{print $1}' b.txt > c.txt
  466  head c.txt
  467  rm c.txt
  468  fgrep -f a.txt b.txt | awk -F'\t' '{print $1,$2}'> c.txt
  469  head c.txt
  470  fgrep -f a.txt b.txt > c.txt
  471  cd /mnt/scratch/hyeyeon/CS131
  472  ls -atlr
  473  ls
  474  time python3 numbers.py
  475  cut -f9 amazon_reviews_us_Books_v1_02.tsv | head
  476  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n |head
  477  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n | tail
  478  time python3 numbers.py
  479  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n | tail -1
  480  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n | head -1
  481  cd /mnt/scratch/hyeyeon/CS131
  482  ls -atlr
  483  vi numbers.sh
  484  chmod 755 numbers.sh
  485  ./numbers.sh
  486  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n > helpful_votes.txt
  487  #!/bin/bash
  488  count=wc -l helpful_votes.txt
  489  count helpful_votes.txt | wc -l
  490  count=helpful_votes.txt |wc -l
  491  wc -l helpful_votes.txt 
  492  wc helpful_votes.txt 
  493  wc -l helpful_votes.txt 
  494  wc helpful_votes.txt 
  495  wc -l helpful_votes.txt | cut -f1
  496  wc -l helpful_votes.txt | awk '{print $1}'
  497  #!/bin/bash
  498  count=wc -l helpful_votes.txt | awk '{print $1}'
  499  count=$"wc -l helpful_votes.txt | awk '{print $1}'"
  500  echo $count
  501  count=$'wc -l helpful_votes.txt | awk '{print $1}''
  502  count='wc -l helpful_votes.txt | awk '{print $1}'
  503  count='wc -l helpful_votes.txt | awk '{print $1}'
  504  count='wc -l helpful_votes.txt | awk '{print $1}'
  505  count='wc -l helpful_votes.txt | awk '{print $1}'
  506  count=$(wc -l helpful_votes.txt | awk '{print $1}')
  507  echo $count
  508  vi numbers.sh
  509  ./numbers.sh
  510  #!/bin/bash
  511  count=$(wc -l helpful_votes.txt | awk '{print $1}')
  512  max=$(tail -1 helpful_votes.txt)
  513  min=$(head -1 helpful_votes.txt)
  514  echo "max : $max /  min : $min"
  515  for i in 'helpful_votes.txt'; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "avg : scale=2; $total / $count" | bc ; done
  516  cd /mnt/scratch/hyeyeon/CS131
  517  #!/bin/bash
  518  count=$(wc -l helpful_votes.txt | awk '{print $1}')
  519  max=$(tail -1 helpful_votes.txt)
  520  min=$(head -1 helpful_votes.txt)
  521  for i in 'helpful_votes.txt'; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  522  cd /mnt/scratch/hyeyeon/CS131
  523  ls -atlr
  524  head helpful_votes.txt
  525  tail helpful_votes.txt
  526  #!/bin/bash
  527  count=$(wc -l helpful_votes.txt | awk '{print $1}')
  528  for i in 'helpful_votes.txt'; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  529  cd /mnt/scratch/hyeyeon/CS131
  530  ls
  531  rm numbers.sh
  532  #!/bin/bash
  533  count=0
  534  total=0
  535  for i in 'helpful_votes.txt' ; do total=$(($total+$i)); done
  536  for i in "helpful_votes.txt" ; do total=$(($total+$i)); done
  537  for i in helpful_votes.txt ; do total=$(($total+$i)); done
  538  tmux attach -t homework
  539  time python3 numbers.py
  540  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n > helpful_votes.txt
  541  vi numbers.sh
  542  chmod 755 numbers.sh
  543  ./numbers.sh
  544  history > cmds.log
  545  tail cmds.log
  546  tmux new-session -s homework
  547  cd /mnt/scratch/hyeyeon/CS131
  548  ls
  549  rm helpful_votes.txt 
  550  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n > helpful_votes.tsv
  551  #!/bin/bash
  552  toal=0
  553  for i in 'helpful_votes.tsv' ; do total=$(($total+$i)); done
  554  for i in 'helpful_votes.tsv' ; do count=0; total=0; for i in $(awk '{print $1;}' $i); do toal=$(echo $total+$i | bc); ((count++)); done;  echo "scale=2; $total / $count" | bc; done
  555  rm helpful_votes.tsv 
  556  sed -n "2, \$p" amazon_reviews_us_Books_v1_02.tsv | cut -f9 | sort -n > helpful_votes.txt
  557  #!/bin/bash
  558  total=0
  559  for i in 'helpful_votes.txt'; do total=$(($total+$i)); done
  560  sum_of_nums=$(cat helpful_votes.txt | awk '{sum += $1} END {print sum}')
  561  echo $sum_of_nums
  562  avg=$(($total/$count))
  563  echo $avg
  564  count=$(wc -l helpful_votes.txt | awk '{print $1}')
  565  avg=$(($total/$count))
  566  echo $avg
  567  echo $count
  568  avg=$(($sum_of_nums/$count))
  569  echo $avg
  570  count=$(wc -l helpful_votes.txt | awk '{print $1}')
  571  max=$(tail -1 helpful_votes.txt)
  572  min=$(head -1 helpful_votes.txt)
  573  echo "count : $count / max : $max /  min : $min / sum_of_nums : $sum_of_nums /  avg : $avg"
  574  start='date +%s.%N'
  575  finish='date +%s.%N'
  576  diff=$( echo "$finish - $start" | bc -l )
  577  diff=$(($finish - $start))
  578  start="date +%s.%N"
  579  finish="date +%s.%N"
  580  diff=$( echo "$finish - $start" | bc -l )
  581  echo "Run Time :  $diff "
  582  finish="date +%s.%N"
  583  diff=$(($finish-$start))
  584  echo "Run Time :  $diff "
  585  start="date +%s.%N"
  586  finish="date +%s.%N"
  587  diff=$(($finish-$start))
  588  echo "Run Time :  $diff"
  589  StartTime=$(date +%s)
  590  EndTime=$(date +%s)
  591  echo "Run TIme : $(($EndTime - $StartTime))"
  592  StartTime=$(date +%s.%N)
  593  Run TIme : 10
  594  [hyeyeon@sjsu CS131]$ StartTime=$(date +%s.%N)
  595  [hyeyeon@sjsu CS131]$
  596  EndTime=$(date +%s.%N)
  597  echo "Run TIme : $(($EndTime - $StartTime))"
  598  vi numbers.sh
  599  chmod 755 numbers.sh
  600  ./numbers.sh
  601  time python3 numbers.py 
  602  ls
  603  rm helpful_votes.txt 
  604  rm numbers.sh
  605  ls
  606  cat 1
  607  ls
  608  script ws10.txt
  609  vi ws10.txt
  610  ls
  611  git init
  612  git remote https://github.com/hyeyeonIm/CS131.git
  613  git remote add git remote add origin https://github.com/hyeyeonIm/CS131.git
  614  git remote add origin https://github.com/hyeyeonIm/CS131.git
  615  git add ws10.txt
  616  git add cmds.log
  617  git commit -m "ws10"
  618  git status
  619  git checkout -b ws10
  620  git branch
  621  git add ws10.txt
  622  git add cmds.log
  623  git commit -m "ws10"
  624  git push -u origin ws10
  625  cd /mnt/scratch/hyeyeon/CS131
  626  cd /mnt/sctrach/hyeyeon/CS131
  627  cd /mnt/scratch/hyeyeon/CS131
  628  ls -atlr
  629  head -2 downloaded_tweets_extend_nolf2.tsv
  630  cut -f6 referenced      in_reply_to_user_id     public_metrics  text_nolf
  631  1520543208614334465     308045021       2022-04-30 23:18:45+00:00       awesomePeopleOnTwitter                          "On top of the chocolate, @benjean2 also included these for my Spanish learning child. I have another child going into Spanish for 2 years and these books, lovingly given, will be out to good use. I hope my kids will be worthy of her kindness. ❤️ #awesomePeopleOnTwitter https://t.co/rGiSjqZXoe"
  632  [hyeyeon@sjsu CS131]$
  633  cut -f6 downloaded_tweets_extend_nolf2.tsv
  634  tmux attach -t homework
  635  grep replied_to downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  636  grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIED.tsv
  637  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS.txt
  638  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS.txt
  639  mkdir infl_replies
  640  for INFL in cat influencers.NOBOTS.txt ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/"//g" > infl_replies/$INFL.hashtags ; done
  641  done
  642  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/"//g" > infl_replies/$INFL.hashtags ; done
  643  for INFL in cat influencers.NOBOTS.txt; do grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/"//g" > infl_replies/$INFL.hashtags
  644  done
  645  for INFL in cat influencers.NOBOTS.txt ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/"//g" > infl_replies/$INFL.hashtags ; done
  646  for INFL in cat influencers.NOBOTS.txt ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/"//g" > infl_replies/$INFL.hashtags ; done
  647  tmux new-session -s homework
  648  rm a5.txt
  649  ls
  650  rm 
  651  rm -rf downloaded_tweets_extend_nolf2_REPLIED.tsv
  652  rm -rf 
  653  rm -rf downloaded_tweets_extend_original_nolf2_REPLIED.tsv 
  654  ls
  655  rm -rf infl_replies/
  656  rm -rf influencers.NOBOTS.txt 
  657  grep replied_to downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  658  grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIED.tsv
  659  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS.txt
  660  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS.txt
  661  mkdir infl_replies
  662  ls
  663  for INFL in cat influencers.NOBOTS.txt ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/"//g" > infl_replies/$INFL.hashtags ; done
  664  for INFL in cat influencers.NOBOTS.txt ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
  665  cd infl_replies
  666  ls
  667  ls -atlr
  668  cd ..
  669  ls
  670  cd infl_replies/
  671  ls
  672  for FILE in 'ls | grep -v replies_hashtag_freqs.tsv' ; do for HASHTAG in 'cat $FILE' ; do count_H_in_C='grep $HASHTAG $FILE' | wc -l'; count_hashtags_in_C='cat $FILE | wc -l'; count_H_entire_dataset='grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l'; count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  673  for FILE in 'ls | grep -v replies_hashtag_freqs.tsv' ; do for HASHTAG in 'cat $FILE' ; do count_H_in_C='grep $HASHTAG $FILE | wc -l'; count_hashtags_in_C='cat $FILE | wc -l'; count_H_entire_dataset='grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l'; count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  674  head replies_hashtag_freqs.tsv
  675  head -5 replies_hashtag_freqs.tsv
  676  cd ..
  677  wc downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  678  awk -F "\t" '{print $4}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | tr "," "\n" | wc
  679  head influencers.NOBOTS.txt
  680  for INFL in cat influencers.NOBOTS.txt ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > /infl_replies/$INFL.hashtags ; done
  681  cd infl_replies/
  682  ls
  683  head influencers.NOBOTS.txt.hashtags
  684  for INFL in 'influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > /infl_replies/$INFL.hashtags ; done
  685  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > /infl_replies/$INFL.hashtags ; done
  686  cd ..
  687  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > /infl_replies/$INFL.hashtags ; done
  688  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
  689  cd infl_replies/
  690  ls
  691  cd ..
  692  for INFL in 'influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
  693  cd infl_replies/
  694  ls
  695  cd ..
  696  for INFL in 'influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
  697  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
  698  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > ../infl_replies/$INFL.hashtags ; done
  699  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
  700  for INFL in 'cat influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  701  cd infl_replies/
  702  ls
  703  for INFL in 'influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  704  cd ..
  705  for INFL in 'influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  706  cd infl_replies/
  707  ls
  708  cd ..
  709  for INFL in 'influencers.NOBOTS.txt' ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  710  for INFL in "cat influencers.NOBOTS.txt" ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  711  cd infl_replies/
  712  ls
  713  cd ..
  714  cat influencers.NOBOTS.txt
  715  for INFL in "cat cat influencers.NOBOTS.txt"; do echo $INFL; done
  716  for INFL in 'cat influencers.NOBOTS.txt'; do echo $INFL; done
  717  for INFL in 'cat influencers.NOBOTS'; do echo $INFL; done
  718  for INFL in {cat influencers.NOBOTS.txt}; do echo $INFL; done
  719  for INFL in "${cat influencers.NOBOTS.txt}"; do echo $INFL; done
  720  for INFL in ${cat influencers.NOBOTS.txt}; do echo $INFL; done
  721  for INFL in $(cat influencers.NOBOTS.txt); do echo $INFL; done
  722  for INFL in $(cat influencers.NOBOTS.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  723  cd infl_replies/
  724  ls
  725  cd ..
  726  cd infl_replies/
  727  for FILE in 'ls | grep -v replies_hashtag_freqs.tsv' ; do for HASHTAG in 'cat $FILE' ; do count_H_in_C='grep $HASHTAG $FILE | wc -l'; count_hashtags_in_C='cat $FILE | wc -l'; count_H_entire_dataset='grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l'; count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  728  sort -k3 replies_hashtag_freqs.tsv
  729  cat replies_hashtag_freqs.tsv
  730  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in 'cat $FILE' ; do count_H_in_C='grep $HASHTAG $FILE | wc -l'; count_hashtags_in_C='cat $FILE | wc -l'; count_H_entire_dataset='grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l'; count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  731  cat replies_hashtag_freqs.tsv
  732  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  733  for FILE in 'ls | grep -v replies_hashtag_freqs.tsv' ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  734  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "hashtag_H   cluster_C_leader(userID)   relative_frequency_H_C  frequency_H_in_C  frequency_H_overall   count_H_in_C   count_hashtags_in_C   count_H_entire_dataset    count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  735  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv); do for HASHTAG in $(cat $FILE); do echo $HASHTAG; done; doen; done
  736  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv); do for HASHTAG in $FILE; do echo $HASHTAG; done; doen; done
  737  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv); do for HASHTAG in $($FILE); do echo $HASHTAG; done; doen; done
  738  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv); do for HASHTAG in $(cat $FILE); do echo $HASHTAG; done; doen; done
  739  ls
  740  head replies_hashtag_freqs.tsv
  741  for FILE in 'ls | grep -v replied_hasgtags_stats.tsv'; do for HASHTAG in 'cat $FILE'; do count_H_in_C='grep $HASGTAG $FILE | wc -l'; done; echo "HASGTAG : $HASGTAG"; echo "count_H_in_C : $count_H_in_C"; done
  742  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall='echo "$count_H_entire_dataset / $count_hasgtags_entire_dataset" | bc -l'; relative_frequency_H_C='echo "$frequency_H_in_C / $frequency_H_overall" | bc -l'; echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  743  head replies_hashtag_freqs.tsv
  744  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C='echo "$count_H_in_C / $count_hashtags_in_C" | bc -l'; frequency_H_overall=$(($count_H_entire_dataset / $count_hasgtags_entire_dataset)); relative_frequency_H_C=$(($frequency_H_in_C / $frequency_H_overall)); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  745  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(($count_H_in_C/$count_hashtags_in_C))'; frequency_H_overall=$(($count_H_entire_dataset/$count_hasgtags_entire_dataset)); relative_frequency_H_C=$(($frequency_H_in_C/$frequency_H_overall)); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  746  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(($count_H_in_C/$count_hashtags_in_C)); frequency_H_overall=$(($count_H_entire_dataset/$count_hasgtags_entire_dataset)); relative_frequency_H_C=$(($frequency_H_in_C/$frequency_H_overall)); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  747  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$($count_H_in_C/$count_hashtags_in_C | bc -l); frequency_H_overall=$($count_H_entire_dataset/$count_hasgtags_entire_dataset | bc -l); relative_frequency_H_C=$($frequency_H_in_C/$frequency_H_overall | bc -l); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  748  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=echo $($count_H_in_C/$count_hashtags_in_C | bc -l); frequency_H_overall=echo $($count_H_entire_dataset/$count_hasgtags_entire_dataset | bc -l); relative_frequency_H_C=echo $($frequency_H_in_C/$frequency_H_overall | bc -l); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  749  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(expr $count_H_in_C/$count_hashtags_in_C); frequency_H_overall=$(expr $count_H_entire_dataset/$count_hasgtags_entire_dataset); relative_frequency_H_C=$(expr $frequency_H_in_C/$frequency_H_overall); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  750  head replies_hashtag_freqs.tsv
  751  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$("scale = 3; $count_H_in_C/$count_hashtags_in_C" | bc -l); frequency_H_overall=$("scale = 3; $count_H_entire_dataset/$count_hasgtags_entire_dataset" | bc -l); relative_frequency_H_C=$("scale = 3; $frequency_H_in_C/$frequency_H_overall" |bc -l); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  752  head replies_hashtag_freqs.tsv
  753  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$("$count_H_in_C/$count_hashtags_in_C" | bc -l); frequency_H_overall=$("$count_H_entire_dataset/$count_hasgtags_entire_dataset" | bc -l); relative_frequency_H_C=$("$frequency_H_in_C/$frequency_H_overall" |bc -l); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  754  head replies_hashtag_freqs.tsv
  755  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(expr $count_H_in_C/$count_hashtags_in_C); frequency_H_overall=$(expr $count_H_entire_dataset/$count_hasgtags_entire_dataset); relative_frequency_H_C=$(expr $frequency_H_in_C/$frequency_H_overall); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  756  head replies_hashtag_freqs.tsv 
  757  tail replies_hashtag_freqs.tsv 
  758  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo $($count_H_in_C/$count_hashtags_in_C | bc -l)); frequency_H_overall=$(echo $($count_H_entire_dataset/$count_hasgtags_entire_dataset | bc -l)); relative_frequency_H_C=$(echo $($frequency_H_in_C/$frequency_H_overall | bc -l)); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  759  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$($count_H_in_C/$count_hashtags_in_C | bc -l); frequency_H_overall=$($count_H_entire_dataset/$count_hasgtags_entire_dataset | bc -l); relative_frequency_H_C=$($frequency_H_in_C/$frequency_H_overall | bc -l); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  760  tail replies_hashtag_freqs.tsv 
  761  head replies_hashtag_freqs.tsv 
  762  #!/bin/bash
  763  a=1
  764  b=7
  765  c=a/b
  766  echo c
  767  c=$($a/$b)
  768  c=$(($a/$b))
  769  echo c
  770  echo $c
  771  cd /mnt/scratch/hyeyeon/CS131
  772  ls -atlr
  773  cut -f6 downloaded_tweets_extend_nolf2.tsv | head -6
  774  cut -f1,4,6 downloaded_tweets_extend_nolf2.tsv | head -6
  775  grep replied_to downloaded_tweets_extend_nolf2.tsv | head
  776  grep replied_to downloaded_tweets_extend_nolf2.tsv |head
  777  cut -f5 downloaded_tweets_extend_nolf2.tsv | head -3
  778  script a5.txt
  779  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928;  frequency_H_in_C=$(($count_H_in_C/$count_hashtags_in_C)); frequency_H_overall=$(($count_H_entire_dataset/$count_hasgtags_entire_dataset));  relative_frequency_H_C=$(($frequency_H_in_C/$frequency_H_overall)); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  780  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(($count_H_in_C/$count_hashtags_in_C));frequency_H_overall=$(($count_H_entire_dataset/$count_hasgtags_entire_dataset)); relative_frequency_H_C=$(($frequency_H_in_C/$frequency_H_overall));echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  781  head replies_hashtag_freqs.tsv 
  782  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(scale=3; $count_H_in_C/$count_hashtags_in_C | bc);frequency_H_overall=$(scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset|bc); relative_frequency_H_C=$(scale=3; $frequency_H_in_C/$frequency_H_overall | bc);echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  783  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo ($count_H_in_C/$count_hashtags_in_C));frequency_H_overall=$(echo ($count_H_entire_dataset/$count_hasgtags_entire_dataset)); relative_frequency_H_C=$(echo ($frequency_H_in_C/$frequency_H_overall));echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  784  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(expr $count_H_in_C/$count_hashtags_in_C); frequency_H_overall=$(expr $count_H_entire_dataset/$count_hasgtags_entire_dataset); relative_frequency_H_C=$(expr $frequency_H_in_C/$frequency_H_overall); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  785  cd infl_replies/
  786  ls
  787  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(scale=3; $count_H_in_C/$count_hashtags_in_C | bc);frequency_H_overall=$(scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset|bc); relative_frequency_H_C=$(scale=3; $frequency_H_in_C/$frequency_H_overall | bc);echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  788  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(expr $count_H_in_C/$count_hashtags_in_C); frequency_H_overall=$(expr $count_H_entire_dataset/$count_hasgtags_entire_dataset); relative_frequency_H_C=$(expr $frequency_H_in_C/$frequency_H_overall); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  789  head replies_hashtag_freqs.tsv 
  790  sort -k3 replies_hashtag_freqs.tsv
  791  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo "scale=2; $count_H_in_C/$count_hashtags_in_C" | bc);frequency_H_overall=$(echo "scale=2; $count_H_entire_dataset/$count_hasgtags_entire_dataset" | bc);relative_frequency_H_C=$(echo "scale=2; $frequency_H_in_C/$frequency_H_overall" | bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  792  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C" | bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset" | bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall" | bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  793  #!/bin/bash
  794  a=2
  795  b=7
  796  c="a/b |bc"
  797  echo $c
  798  c="a/b"|bc
  799  echo $c
  800  c=$("a/b"|bc)
  801  c=$(a/b|bc)
  802  c=$a/b|bc)
  803  c="$a/$b|bc"
  804  echo $c
  805  c="$a/$b"|bc
  806  echo $c
  807  c="scale=2 ;$a/$b" bc
  808  echo "scale=3;$a/$b"| bc
  809  a=1
  810  b=4
  811  echo "scale=3;$a/$b"| bc
  812  tmux attach -t homework
  813  grep replied_to downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  814  grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIED.tsv
  815  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS.txt
  816  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS.txt
  817  awk -F "\t" '{print $4}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | tr "," "\n" | wc
  818  mkdir infl_replies
  819  for INFL in $(cat influencers.NOBOTS.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  820  cd infl_replies
  821  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=7754; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C"|bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset"|bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"|bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  822  sort -k3 replies_hashtag_freqs.tsv
  823  sort -k3 replies_hashtag_freqs.tsv | head
  824  cd ..
  825  grep retweeted downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_RETWEETED.tsv
  826  grep retweeted downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_RETWEETED.tsv
  827  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS2.txt
  828  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS2.txt
  829  awk -F "\t" '{print $4}' downloaded_tweets_extend_original_nolf2_RETWEETED.tsv | tr "," "\n" | wc
  830  awk -F "\t" '{print $4}'  downloaded_tweets_extend_nolf2_RETWEETED.tsv | tr "," "\n" | wc
  831  mkdir infl_retweet
  832  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s\/"//g" > infl_retweet/${INFL}".hashtags ; done
  833  cd infl_retweet
  834  ls
  835  cd ..
  836  head influencers.NOBOTS2.txt
  837  head  downloaded_tweets_extend_original_nolf2_RETWEETED.tsv
  838  head downloaded_tweets_extend_nolf2_RETWEETED.tsv
  839  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s\/"//g" > infl_retweet/${INFL}".hashtags ; done
  840  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_retweet/${INFL}".hashtags ; done
  841  tmux new-session -s homework
  842  tmux attach -t homework
  843  grep replied_to downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  844  grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIED.tsv
  845  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS.txt
  846  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS.txt
  847  awk -F "\t" '{print $4}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | tr "," "\n" | wc
  848  mkdir infl_replies
  849  for INFL in $(cat influencers.NOBOTS.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  850  cd infl_replies
  851  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=7754; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C"|bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset"|bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"|bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  852  sort -k3 replies_hashtag_freqs.tsv | head
  853  cd ..
  854  grep retweeted downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_RETWEETED.tsv
  855  grep retweeted downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_RETWEETED.tsv
  856  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS2.txt
  857  awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS2.txt
  858  awk -F "\t" '{print $4}'  downloaded_tweets_extend_nolf2_RETWEETED.tsv | tr "," "\n" | wc
  859  mkdir infl_retweet
  860  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_retweet/"${INFL}".hashtags ; done
  861  cd infl_retweet
  862  for FILE in $(ls | grep -v retweets_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=63068; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C"|bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset"|bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"|bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > retweets_hashtag_freqs.tsv
  863  sort -k3 retweets_hashtag_freqs.tsv | head
  864  cd /mnt/scratch/hyeyeon/CS131
  865  cd infl_replies/
  866  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C");frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset");relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  867  head replies_hashtag_freqs.tsv 
  868  #!/bin/bash
  869  a=1
  870  b=5
  871  echo "scale=3;$a/$b"
  872  c=$(echo "scale=3;$a/$b")
  873  c=$("scale=3;$a/$b")
  874  echo "scale=3;$a/$b"| bc
  875  c=$(echo "scale=3;$a/$b"|bc)
  876  echo $c
  877  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C"|bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset"|bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"|bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  878  head replies_hashtag_freqs.tsv 
  879  tail replies_hashtag_freqs.tsv 
  880  cd ..
  881  rm -rf infl_replies
  882  mkdir infl_replies
  883  for INFL in $(cat influencers.NOBOTS.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/"${INFL}".hashtags ; done
  884  cd infl_replies/
  885  ls
  886  for FILE in $(ls | grep -v replies_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=3928; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C"|bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset"|bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"|bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > replies_hashtag_freqs.tsv
  887  cd ..
  888  ls
  889  rm -rf infl_replies
  890  rm -rf 
  891  downloaded_tweets_extend_nolf2_REPLIED.tsv 
  892  rm -rf downloaded_tweets_extend_nolf2_REPLIED.tsv
  893  rm -rf downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  894  rm -rf influencers.NOBOTS.txt
  895  ls
  896  rm -rf replies_hashtag_freqs.tsv
  897  script a5.txt
  898  rm a5.txt
  899  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_retweet/${INFL}".hashtags ; done
  900  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_retweet/${INFL}".hashtags ; done
  901  for INFL in $(cat influencers.NOBOTS2.txt) ; do  grep $INFL downloaded_tweets_extend_original_nolf2_RETWEETED.tsv  downloaded_tweets_extend_nolf2_RETWEETED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_retweet/"${INFL}".hashtags ; done
  902  cd infl_retweet
  903  for FILE in $(ls | grep -v retweets_hashtag_freqs.tsv) ; do for HASHTAG in $(cat $FILE) ; do count_H_in_C=$(grep $HASHTAG $FILE | wc -l); count_hashtags_in_C=$(cat $FILE | wc -l); count_H_entire_dataset=$(grep $HASHTAG ../downloaded_tweets_extend_original_nolf2_REPLIED.tsv | wc -l); count_hashtags_entire_dataset=63068; frequency_H_in_C=$(echo "scale=3; $count_H_in_C/$count_hashtags_in_C"|bc);frequency_H_overall=$(echo "scale=3; $count_H_entire_dataset/$count_hasgtags_entire_dataset"|bc);relative_frequency_H_C=$(echo "scale=3; $frequency_H_in_C/$frequency_H_overall"|bc); echo "$HASHTAG   $FILE   $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall   $count_H_in_C   $count_hashtags_in_C   $count_H_entire_dataset    $count_hashtags_entire_dataset" ; done; done > retweets_hashtag_freqs.tsv
  904  sort -k3 retweets_hashtag_freqs.tsv | head
  905  cd ..
  906  ls
  907  rm -rf downloaded_tweets_extend_nolf2_REPLIED.tsv
  908  rm -rf downloaded_tweets_extend_nolf2_RETWEETED.tsv
  909  rm -rf downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  910  rm -rf downloaded_tweets_extend_original_nolf2_RETWEETED.tsv
  911  rm -rf infl_replies
  912  rm -rf infl_retweet
  913  rm -rf influencers.NOBOTS2.txt
  914  rm -rf influencers.NOBOTS.txt
  915  ls
  916  script a5.txt
  917  vi a5.txt
  918  git init
  919  git checkout -b a5
  920  git branch
  921  git add a5.txt
  922  git commit -m "a5"
  923  git push -u origin a5
  924  cd mnt/scratch/hyeyeon/CS131
  925  cd ..
  926  pwd
  927  ls
  928  cd mnt
  929  ls
  930  cd scratch
  931  cd hyeyeon
  932  cd CS131
  933  ls
  934  head downloaded_tweets_extend_nolf2_REPLIED.tsv
  935  cd /mnt/scratch/hyeyeon/CS131
  936  ls
  937  ls -atlr
  938  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6) && ($1 >=3)' |  sort | uniq -c | sort -n -k1> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  939  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  940  head downloaded_tweets_extend_nolf2.tsv
  941  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6)' |  sort | uniq -c | sort -n -k1 | awk '($1 >=3)' > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  942  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  943  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6)' |  sort | uniq -c | sort -n -k1 | awk -F "\t" '($1 >=3)' > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  944  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  945  rm downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  946  ls
  947  head downloaded_tweets_extend_nolf2.tsv 
  948  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6)' |  sort | uniq -c | sort -n -k1 | awk '($1 >=3) {print}' > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  949  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  950  rm downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  951  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6) {print}' |  sort | uniq -c | sort -n -k1 | awk '($1 >=3) {print}' > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  952  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  953  rm downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  954  grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  955  head downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  956  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv| sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print}' >> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  957  head downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  958  awk -F "\t" '($2 != $6)' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv| sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print}' >> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  959  head downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  960  cut -f2,6  downloaded_tweets_extend_original_nolf2_REPLIED.tsv
  961  awk -F "\t" '($2 != $6) {print $1,$2,$3,$4,$5,$6,$7,$8,}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $1,$2,$3,$4,$5,$6,$7,$8,}' > downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  962  awk -F "\t" '($2 != $6) {print $1,$2,$3,$4,$5,$6,$7,$8}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $1,$2,$3,$4,$5,$6,$7,$8}' > downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  963  head downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  964  rm downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  965  awk -F "\t" '($2 != $6)' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv >> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  966  grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  967  awk -F "\t" '($2 != $6)' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv >> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  968  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv >> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  969  ls
  970  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  971  awk -F "\t" '($2 != $6) { print }' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv | sort | uniq -c | sort -n -k1 >> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  972  rm downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  973  ls
  974  rm downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  975  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6) { print }' | sort | uniq -c | sort -n -k1 | awk '($1 >=3) { print }' > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  976  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  977  ls
  978  rm downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
  979  head downloaded_tweets_extend_nolf2_REPLIED.tsv
  980  awk -F "\t" '($2 != $6) { print }' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) { print }' > downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  981  head downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
  982  awk '{print}' v3.txt
  983  head v3.txt
  984  head helpful_votes.txt
  985  awk '{print}' helpful_votes.txt
  986  ls
  987  head a5.txt
  988  cd /mnt/scratch/hyeyeon/CS131
  989  ls
  990  head infl_replies
  991  head star_rating.tsv
  992  awk '{print}' star_rating.tsv | head
  993  awk '{print}' star_rating.tsv | sort
  994  head downloaded_tweets_extend_nolf2_REPLIED.tsv
  995  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | head
  996  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k1 | awk '($1 >=3) { print }' | head
  997  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k1 | awk -F "\t" '($1 >=3) {print}' | head
  998  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k1 | awk '{print $1}' | head
  999  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k1 | awk '($1 >= 3) {print}' | head
 1000  awk -F "\t" '($2 != $6) {print}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k1 | awk '{print $1}' | tail
 1001  head influencers.NOBOTS.txt
 1002  ls -atlr
 1003  ls
 1004  rm downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
 1005  ls
 1006  mkdir test
 1007  cd test
 1008  cp "/mnt/scratch/hyeyeon/CS131/downloaded_tweets_extend_nolf2.tsv"
 1009  cd ..
 1010  cp "/mnt/scratch/hyeyeon/CS131/downloaded_tweets_extend_nolf2.tsv" /test
 1011  cp "/mnt/scratch/hyeyeon/CS131/downloaded_tweets_extend_nolf2.tsv" /mnt/scratch/hyeyeon/CS131/test/
 1012  cp "/mnt/scratch/hyeyeon/CS131/downloaded_tweets_extend_original_nolf2.tsv" /mnt/scratch/hyeyeon/CS131/test/
 1013  cd test
 1014  ls
 1015  ls -atlr
 1016  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '($2 != $6) { print }' | sort | uniq -c | sort -n -k1 > downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
 1017  grep replied_to downloaded_tweets_extend_original_nolf2.tsv | awk -F "\t" '($2 != $6) { print }' | sort | uniq -c | sort -n -k1 > downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
 1018  awk -F "\t" '{print $6}' *NOBOTS.tsv | wc
 1019  awk -F "\t" '{print $2}' *NOBOTS.tsv | wc
 1020  awk -F "\t" '{print $6}' *NOBOTS.tsv | sort | uniq -c |  sort -n -k1 | head
 1021  awk -F "\t" '{print $6}' *NOBOTS.tsv | sort | uniq -c |  sort -n -k1 | wc
 1022  awk -F "\t" '{print $2}' *NOBOTS.tsv | sort | uniq -c |  sort -n -k1 | wc
 1023  awk -F "\t" {print $6}' *NOBOTS.tsv| sort | uniq -c |  sort -n -k1 | awk '{print $2}' > inusers.txt
awk -F "\t" {print $6}' *NOBOTS.tsv | sort | uniq -c |  sort -n -k1 | awk '{print $2}' > inusers.txt
 1024  awk -F "\t" '{print $6}' *NOBOTS.tsv | sort | uniq -c |  sort -n -k1 | awk '{print $2}' > inusers.txt
 1025  awk -F "\t" '{print $2}' *NOBOTS.tsv > user.txt
 1026  for id in $(cat inusers.txt); do  grep $id user.txt > userWhoReplied.txt; done
 1027  userWhoReplied.txt | wc
 1028  userWhoReplied.txt | head
 1029  awk -F "\t" {print $6}' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv| sort | uniq -c | sort -n -k1 | awk '($1 >=3) {print $2}' > influencers.txt
 1030  awk -F "\t" '{print $6}' downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv | sort | uniq -c | sort -n -k1 | awk '($1 >=3) {print $2}' > influencers.txt
 1031  awk -F "\t" '{print $6}' downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv| sort | uniq -c | sort -n -k1 | awk '($1 >=3) {print $2}' >> influencers.txt
 1032  head influencers.txt
 1033  for INFL in $(cat influencers.txt); do  grep $INFL downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv > influencers.tsv ; done
 1034  head influencers.tsv
 1035  awk '{print $3}' influencers.tsv | sort | uniq -c | sort -nr -k 1 | head
 1036  for INFL in $(cat influencers.txt); do  grep $INFL downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv  downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv > influencers.tsv ; done
 1037  head influencers.tsv
 1038  for INFL in $(cat influencers.txt); do  grep $INFL *NOBOTS.tsv > influencers.tsv ; done
 1039  head influencers.tsv
 1040  rm influencers.tsv
 1041  for INFL in $(cat influencers.txt); do  grep $INFL *NOBOTS.tsv > influencers.tsv ; done
 1042  head influencers.tsv
 1043  head downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv
 1044  head downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
 1045  head influencers.txt
 1046  for INFL in $(cat influencers.txt); do  grep $INFL *NOBOTS.tsv > influencers.tsv ; done
 1047  head influencers.tsv
 1048  for INFL in $(cat influencers.txt); do grep $INFL *NOBOTS.tsv > influencers.tsv ; done
 1049  head influencers.tsv
 1050  awk '{print $4}' influencers.tsv | sort | uniq -c | sort -nr -k 1 | head
 1051  awk '{print $5}' influencers.tsv | sort | uniq -c | sort -nr -k 1 | head
 1052  rm influencers.tsv 
 1053  for INFL in $(cat influencers.txt); do grep $INFL downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv > influencers.tsv ; done
 1054  for INFL in $(cat influencers.txt); do grep $INFL downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv >> influencers.tsv ; done
 1055  head -5 influencers.tsv 
 1056  awk '{print $4}' influencers.tsv | sort | uniq -c | sort -nr -k1 | head
 1057  awk '{print $8}' influencers.tsv 
 1058  awk '{print $9}' influencers.tsv 
 1059  awk '{print $10}' influencers.tsv | head 
 1060  head influencers.tsv
 1061  ls
 1062  head -2 downloaded_tweets_extend_nolf2.tsv
 1063  cut -f9  influencers.tsv | head 
 1064  cut -f8 influencers.tsv | head 
 1065  cut -f7 influencers.tsv | head 
 1066  cut -f6 influencers.tsv | head 
 1067  cut -f8 influencers.tsv | head 
 1068  cut -f8 influencers.tsv > tweet.txt
 1069  sed 's/<[^>]*>//g' tweet.txt | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' >>  tweet.txt 
 1070  tweet.txt | head
 1071  head tweet.txt
 1072  sed 's/<[^>]*>//g' tweet.txt | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' > tweet.txt 
 1073  tweet.txt|head
 1074  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' > tweet.txt 
 1075  tweet.txt |head
 1076  cut -f8 influencers.tsv > tweet.txt
 1077  tweet.txt | head
 1078  head tweet.txt
 1079  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' > tweet.txt 
 1080  head tweet.txt
 1081  tweet.txt
 1082  cut -f8 influencers.tsv > tweet.txt
 1083  sed 's/<[^>]*>//g' tweet.txt 
 1084  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g'
 1085  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'
 1086  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g' >> tweet.txt 
 1087  tweet.txt
 1088  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'
 1089  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g' > remove.txt
 1090  remove.txt
 1091  ls
 1092  rm remove.txt
 1093  tweet.txt
 1094  rm tweet.txt
 1095  ls
 1096  cut -f8 influencers.tsv > tweet.txt
 1097  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'>tweet1.txt 
 1098  tweet1.txt
 1099  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g' 
 1100  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g' > tweet1.tsv
 1101  tweet1.tsv
 1102  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'
 1103  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' tweet.txt | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' > tweet1.txt 
 1104  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' tweet.txt | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g'
 1105  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' tweet.txt | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' > vi tweet1.txt
 1106  tweet1.txt
 1107  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' tweet.txt | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' > tweet1.txt
 1108  tweet1.txt
 1109  vi tweet1.txt
 1110  ls
 1111  rm tweet1.txt
 1112  rm tweet1.tsv
 1113  head tweet.txt
 1114  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' tweet.txt | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' > tweet1.txt
 1115  head tweet1.txt
 1116  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' tweet.txt | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' | head
 1117  head tweet.txt
 1118  sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/\@//g' | sed 's/\"//g'| sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' >tweet1.txt 
 1119  head tweet1.txt
 1120  tr -c '[:alnum:]' '[\n*]' < tweet1.txt | sort | uniq -c | sort -nr | head  -30
 1121  tr -c '[:alnum:]' '[\n*]' < tweet1.txt | sort | uniq -c | sort -nr | head  -50
 1122  inusers.txt
 1123  ls
 1124  head inusers.txt
 1125  inusers.txt | wc
 1126  cat inusers.txt
 1127  head user.txt
 1128  rm user.txt
 1129  awk -F "\t" '{print $2}' *NOBOTS.tsv  | sort | uniq -c |  sort -n -k1 | awk '{print $2}' > user.txt
 1130  head user.txt
 1131  grep 1004484314 user.txt
 1132  for id in $(cat inusers.txt); do grep $id user.txt > userWhoReplied.txt; done
 1133  cat userWhoReplied.txt
 1134  userWhoReplied.txt | wc
 1135  cat userWhoReplied.txt  | wc
 1136  ls -atlr
 1137  rm vi
 1138  cd ..
 1139  ls
 1140  ls -atlr
 1141  tmux new -s homework
 1142  script a6.txt
 1143  vi a6.txt
 1144  history > cmds.log
