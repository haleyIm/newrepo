Script started on 2022-12-05 20:50:08-05:00

>> Create tmux
]0;hyeyeon@sjsu:/mnt/scratch/hyeyeon/CS131[hyeyeon@sjsu CS131]$ tmux new -s homework
[?1049h[22;0;0t[?1h=[H[2J[?12l[?25h[?1000l[?1002l[?1006l[?1005l[c(B[m[?12;25h[?12l[?25h[?1003l[?1006l[?2004l[1;1H[1;42r]112[1;1H[?25l[K
[K
[30m[42m[homework]0:bash*                     "sjsu.pub.pic2.ibm.com" 20:50 05-Dec-22(B[m[1;1H[?12l[?25h(B[m[?12;25h[?12l[?25h[?1003l[?1006l[?2004l[1;1H[1;42r[1;1H[?25l[K
[30m[42m[homework]0:bash*                     "sjsu.pub.pic2.ibm.com" 20:50 05-Dec-22(B[m[1;1H[?12l[?25h[hyeyeon@sjsu CS131]$ tmux attach -t homework
sessions should be nested with care, unset $TMUX to force


â—Ž Consider the most influential users who got 3 replies or more (just replies, not retweets). 
There are 3 questions:
To answer these questions you should get the replies from both files (using grep replied_to) 
and remove the bots (using awk with $2 != $6), then save as files:
> downloaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv
> downloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv

[hyeyeon@sjsu CS131]$ grep replied_to downloaded_tweets_extend_nolf2.tsv | awkk -F "\t" '($2 != $6) { print }' | sort | uniq -c | sort -n -k1 > downloaded_ttweets_extend_nolf2_REPLIES.NOBOTS.tsv
[hyeyeon@sjsu CS131]$ grep replied_to downloaded_tweets_extend_original_nolf2..tsv | awk -F "\t" '($2 != $6) { print }' | sort | uniq -c | sort -n -k1 > dowwnloaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv


1. How many such influential users exist?

[hyeyeon@sjsu CS131]$ awk -F "\t" '{print $6}' *NOBOTS.tsv | sort | uniq -c |   sort -n -k1 | wc
   5196   10392  111792
-> 5196 users

2. How many users replied to them in total?

[hyeyeon@sjsu CS131]$ awk -F "\t" '{print $2}' *NOBOTS.tsv | sort | uniq -c |   sort -n -k1 | wc
   1667    3334   37094
-> 1667 users

3 How many of the users who replied to the influential users also got replied to from any other user (at least once)?
	1) Arrange 6th column influencers
[hyeyeon@sjsu CS131]$ awk -F "\t" '{print $6}' *NOBOTS.tsv | sort | uniq -c |   sort -n -k1 | awk '{print $2}' > inusers.txt

	2) Check the id in influencers.txt exist in 2nd column
[hyeyeon@sjsu CS131]$ awk -F "\t" '{print $2}' *NOBOTS.tsv  | sort | uniq -c ||  sort -n -k1 | awk '{print $2}' > user.txt
[hyeyeon@sjsu CS131]$ for id in $(cat inusers.txt); do grep $id user.txt > useerWhoReplied.txt; done
[?25l[42d[30m[42m[homework]0:bash*                     "sjsu.pub.pic2.ibm.com" 20:51 05-Dec-22(B[m[21;1H[?12l[?25h[hyeyeon@sjsu CS131]$ cat userWhoReplied.txt  | wc
      1       1      11
-> Just 1 ID
-> Let's check what ID is replied by influencer
[hyeyeon@sjsu CS131]$ cat userWhoReplied.txt  | wc[K[K[K[K[K[K
3453306553


â—Ž For the more influential users who got 3 or more replies do two more tasks:

[hyeyeon@sjsu CS131]$ awk -F "\t" '{print $6}' *NOBOTS.tsv  | sort | uniq -c || sort -n -k1 | awk '($1 >=3) {print $2}' > influencers.txt
[hyeyeon@sjsu CS131]$ for INFL in $(cat influencers.txt); do grep $INFL downlooaded_tweets_extend_nolf2_REPLIES.NOBOTS.tsv > influencers.tsv ; done
[hyeyeon@sjsu CS131]$ for INFL in $(cat influencers.txt); do grep $INFL downlooaded_tweets_extend_original_nolf2_REPLIES.NOBOTS.tsv >> influencers.tsv ; donne


4. Extract the dates of the replies in format YY-MM-DD and 
find the top 10 dates on which the most replies happened.

[hyeyeon@sjsu CS131]$ awk '{print $4}' influencers.tsv | sort | uniq -c | sortt -nr -k1 | head
[1;41r[3S[31;1H     20 2022-02-26
     18 2022-03-05
     18 2022-01-03
     17 2022-04-12
     17 2022-03-18
     16 2022-04-19
     16 2022-02-27
     16 2022-02-23
     16 2022-02-17
     15 2022-04-09[1;42r[41;1H[hyeyeon@sjsu CS131]$ [?25l
[30m[42m[homework]0:bash*                     "sjsu.pub.pic2.ibm.com" 20:52 05-Dec-22(B[m[41;23H[?12l[?25h

5. 
	1) Repeat what you did in worksheets 7 and 8 to find the most frequent words (not considering stopwords) in the tweet text (last column) for those users. 
cut -f8 influencers.tsv > tweet.txt[1;41r[41;77H

[1;42r[41;1H[hyeyeon@sjsu CS131]$ [1;41r[7S[34;23H

	2) Which words are the most frequent in that tweet text? 
-> Remove HTML tag
-> Remove stopwords
sed 's/<[^>]*>//g' tweet.txt | sed 's/\,//g' | sed 's/\..//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed  's/\@//g' | sed 's/\"//g'| sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | ssed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g'' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a///g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sedd 's/not//g' | sed 's/for//g' >tweet1.txt [1;42r[41;1H[hyeyeon@sjsu CS131]$ [1;41r[41;77H
[40;23H

tr -c '[:alnum:]' '[\n*]' < tweet1.txt | sort | uniq -c  | sort -nr | head  -30[1;42r[41;24H[K[K50[1;41r[41;77H
[1;42r[41;1H[1;41r[12S[29;1H  11156 
    293 s
    234 re
    219 tco
    219 https
    213 f
    181 t
    160 tht
    121 hve
    114 mp
    111 wh
    101 on[1;42r[41;1H[1;41r[24S[17;1H     88 y
     87 we
     81 n
     79 T
     71 ll
     70 ws
     68 m
     66 r
     62 h
     61 cn
     60 who
     60 me
     59 my
     59 ir
     59 hs
     54 wht
     53 will
     52 but
     50 You
     49 We
     49 our
     48 do
     46 out
     46 get[1;42r[41;1H[1;41r[14S[27;1H     45 so
     44 from
     43 know
     43 by
     42 up
     41 bout
     40 people
     40 now
     40 en
     39 Th
     37 would
     37 no
     36 need
     36 hd[1;42r[41;1H[hyeyeon@sjsu CS131]$ [1;41r[41;77H
[40;23Hlogout[1;42r[41;1H[1;42r(B[m[?1l>[H[2J]112[?12l[?25h[?1000l[?1002l[?1006l[?1005l[?1049l[23;0;0t[exited]
]0;hyeyeon@sjsu:/mnt/scratch/hyeyeon/CS131[hyeyeon@sjsu CS131]$ exit

	3) Are they what you expected based on the frequent hashtags from previous assignments?
-> Not special words

Script done on 2022-12-05 20:52:31-05:00
