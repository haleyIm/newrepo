    9  git push -u origin a2
   10  git init
   11  git branch
   12  git add a2.txt
   13  ls
   14  git branch master
   15  git checkout master
   16  git branch -d a2
   17  cd CS131
   18  ls
   19  script a2.txt
   20  cut -f2 downloaded_tweets_extend_original_nolf2.tsv|sort -k1|uniq -c|sort -n|tail -10
   21  cut -f6 downloaded_tweets_extend_original_nolf2.tsv|sort -k1|uniq -c|sort -n|tail -10
   22  cut -f1,5 downloaded_tweets_extend_nolf2.tsv|grep -i "retweeted"|sort -k1|uniq -w18 -c|sort -n|tail -10
   23  cut -f4 downloaded_tweets_extend_nolf2.tsv|sort|uniq -c|sort -n|tail -30
   24  cut -f4,5 downloaded_tweets_extend_nolf2.tsv|grep -i "retweeted"|sort -k1|uniq -w10 -c|sort -n|tail -30
   25  cut -f4,6 downloaded_tweets_extend_nolf2.tsv|sort -k1|uniq -w10 -c|sort -n|tail -30
   26  cut -f4,5 downloaded_tweets_extend_nolf2.tsv|grep -i "quoted"|sort -k1|uniq -w10 -c|sort -n|tail -30
   27  vi a2.txt
   28  git init
   29  git add a2.txt
   30  git commit -m "a2"
   31  git checkout -b a2
   32  git add a2.txt
   33  git commit -m "a2"
   34  git push -u origin a2
   35  cd CS131
   36  ls ..
   37  ls
   38  help ls ..
   39  cd ..
   40  ls ..
   41  ls
   42  cd CS131
   43  ls
   44  head downloaded_tweets_extend_nolf2.tsv
   45  cd CS131
   46  ls
   47  fontconfig-2.7.2-1.aix5.1.ppc.rpmexpat-2.0.1-2.aix5.1.ppc.rpm freetype2-2.3.9-1.aix5.1.ppc.rpmzlib-1.2.3-5.aix5.1.ppc.rpm libpng-1.2.40-1.aix5.1.ppc.rpmgd-2.0.35-4.aix5.1.ppc.rpmlibjpeg-7-1.aix5.1.ppc.rpmlibXpm-3.5.7-2.aix5.1.ppc.rpm  gettext-0.17-1.aix5.1.ppc.rpmglib2-2.20.5-1.aix5.1.ppc.rpm
   48  sudo yum install tmux
   49  tmux ls
   50  cd ..
   51  sudo yum install tmux^C
   52  tmux ls
   53  ssh /etc/gnuplot-5.4/src/gnuplot
   54  /etc/gnuplot-5.4/src/gnuplot
   55  ssh4
   56  ssh
   57  /etc/gnuplot-5.4/src/gnuplot
   58  dnf install gcc ; sudo yum install make
   59  sudo yum groupinstall "X Window System" -y 
   60  ssh /etc/gnuplot-5.4.4/src/gnuplot
   61  ssh
   62  /etc/gnuplot-5.4.4/src/gnuplot
   63  ls
   64  head downloaded_tweets_extend_original_nolf2.tsv
   65  cd CS131
   66  ls
   67  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c
   68  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|awk'{if($1 >=3) {print}}'
   69  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n>replies_data.csv
   70  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n
   71  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.csv
   72  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.tsv
   73  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.txt
   74  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n
   75  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.txt
   76  cut -f2,6 head downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n
   77  ls
   78  cut -f2,6 downloaded_tweets_extend_original_nolf2.tsv | tail -10
   79  cut -f2,6 downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n
   80  cut -f2,6 downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.csv
   81  ls
   82  rm replies_data.tsv
   83  rm replies_data.txt
   84  ls
   85  awk '{print $1}' replies_data.csv | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }'
   86  gunplot
   87  gnuplot
   88  ./gunplot
   89  /etc/gnuplot-5.4.4/src/gnuplot
   90  head replies_data.cvs
   91  ls
   92  head replies_data.csv
   93  tail replies_data.cvs
   94  vi replies_data.csv
   95  cd src : ./gnuplot
   96  /etc/gnuplot-5.4.4/src/gnuplot
   97  awk '{print $1}' replies_data.csv | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }' > replies_data.csv
   98  /etc/gnuplot-5.4.4/src/gnuplot
   99  head replies_data.csv
  100  relpies_data
  101  replies_data.csv
  102  ls
  103  replies_data.csv
  104  vi replies_data.csv
  105  cut -f2,6 downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.csv
  106  awk '{print $1}' replies_data.csv | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }' > data.csv
  107  data.csv
  108  ls
  109  vi data.csv
  110  ls
  111  /etc/gnuplot-5.4.4/src/gnuplot
  112  gunplot<<EOF
  113  set title "sin(x)"
  114  set ylabel "y"
  115  set xlabel "x"
  116  plot sin(x)
  117  pause mouse key
  118  EOF
  119  gnuplot << EOF
  120  set title "sin(x)"
  121  set ylabel "y"
  122  set xlabel "x"
  123  plot sin(x)
  124  pause mouse key
  125  EOF
  126  /etc/gnuplot-5.4.4/src/gnuplot
  127  ls
  128  rm test
  129  data.csv
  130  vi data.csv
  131  head replies_data.csv
  132  head data.csv
  133  awk '{print $1}' replies_data.csv | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }'
  134  cut -f2,6 downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n
  135  ls
  136  grep "1000005001" downloaded_tweets_extend_original_nolf2.tsv
  137  grep "1094971056358637568" downloaded_tweets_extend_original_nolf2.tsv
  138  grep "1094971056358637568" downloaded_tweets_extend_original_nolf2.tsv|cut –f4 tap | sort | uniq –c | sort –n| tail -30
  139  grep "1094971056358637568" downloaded_tweets_extend_original_nolf2.tsv|cut –f4 | sort | uniq –c | sort –n| tail -30
  140  grep "1094971056358637568" downloaded_tweets_extend_original_nolf2.tsv|cut -f4|sort|uniq -c|sort -n|tail -30
  141  cut -f4 downloaded_tweets_extend_original_nolf2.tsv|sort|uniq -c|sort -n|tail -30
  142  grep "1094971056358637568" downloaded_tweets_extend_original_nolf2.tsv|cut -f4|sort|uniq -c|sort -n|tail -30 > a3_hashtag.txt
  143  cut -f4 downloaded_tweets_extend_original_nolf2.tsv|sort|uniq -c|sort -n|tail -30 > a2_hashtag.txt
  144  diff a3_hashtag.txt a2_hashtag.txt
  145  ls
  146  rm data.csv
  147  rm a2_hashtag.txt
  148  rm a3_hashtag.txt
  149  rm a.svg
  150  rm replies_data.csv
  151  ls
  152  script a3.txt
  153  tmux new-session -s homework
  154  cd CS131
  155  ls
  156  list = amazon_reviews_us_Books_v1_02.tsv | cut –f2
  157  #!/bin/bash
  158  list = amazon_reviews_us_Books_v1_02.tsv | cut –f2
  159  cd CS131
  160  ls
  161  a=3
  162  b=2
  163  a+b
  164  ls
  165  cd CS131
  166  ls
  167  head amazon_reviews_us_Books_v1_02.tsv
  168  cd CS131
  169  ls
  170  head amazon_reviews_us_Books_v1_02.tsv
  171  for i in cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|tail -1000
  172  do
  173  echo $i
  174  done
  175  for i in cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|tail -1000
  176  #!/bin/bash
  177  for i in cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|tail -1000
  178  for i in 1 2 3; do echo $i; done
  179  list = cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|tail -1000
  180  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|tail -1000
  181  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000
  182  cd CS131
  183  ls
  184  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000
  185  cd CS131
  186  ls
  187  for i in {1...1000}; do name = sed -n '{$i}p' amazon_reviews_us_Books_v1_02.tsv|cut -f1; donefor i in {1...1000}; do name = sed -n '{$i}p' amazon_reviews_us_Books_v1_02.tsv|cut -f1; done
  188  #!/bin/bash
  189  for i in {1...1000}; do name=sed -n '{$i}p' amazon_reviews_us_Books_v1_02.tsv|cut -f1; done
  190  mkdir TEST
  191  for i in {1...1000}; do name = sed -n '{$i}p' amazon_reviews_us_Books_v1_02.tsv|cut -f1; vi CUSTOMER/name.txt; done
  192  ls
  193  cd TEST
  194  ls
  195  cd ..
  196  cd CS131
  197  ls
  198  tmux attach -t homework
  199  Ctrl+B followed by C
  200  s
  201  ls
  202  cut -f2,6 downloaded_tweets_extend_original_nolf2.tsv|sort -k2|uniq -f1 -c|sort -n > replies_data.csv
  203  tail replies_data.csv
  204  awk '{print $1}' replies_data.csv | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }'
  205  awk '{print $1}' replies_data.csv | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }' > data.csv
  206  /etc/gnuplot-5.4.4/src/gnuplot
  207  grep "1094971056358637568" downloaded_tweets_extend_original_nolf2.tsv|cut -f4|sort|uniq -c|sort -n|tail -30 > a3_hashtag.txt
  208  cut -f4 downloaded_tweets_extend_original_nolf2.tsv|sort|uniq -c|sort -n|tail -30 > a2_hashtag.txt
  209  diff a3_hashtag.txt a2_hashtag.txt
  210  ls
  211  vi a3.txt
  212  git init
  213  git branch
  214  git checkout -b a3
  215  git branch
  216  git add a3.txt
  217  git commit -m "a3"
  218  git remote https://github.com/hyeyeonIm/CS131.git
  219  git push -u origin a3
  220  cd CS131
  221  ls
  222  for i in {1...1000}; do name = sed -n '{$i}p' amazon_reviews_us_Books_v1_02.tsv|cut -f1; vi grep -n"name" amazon_reviews_us_Books_v1_02.tsv|cut -f13,14>Test/name.txt; done
  223  NAME = (amazon_reviews_us_Books_v1_02.tsv | cut –f2)
  224  NAME = amazon_reviews_us_Books_v1_02.tsv | cut –f2
  225  NAME = cut -f2 amazon_reviews_us_Books_v1_02.tsv
  226  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000
  227  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1
  228  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1>test.txt
  229  for name in test.txt; do grep -n "name" amazon_reviews_us_Books_v1_02.tsv|cut -f13,14 > TEST/name.txt; done
  230  cd TEST
  231  ls
  232  vi name.txt
  233  vi test.txt
  234  ls
  235  cd ..
  236  vi test.txt
  237  for name in test.txt; do echo "NAME: $name"; done
  238  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f2
  239  for name in cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1
  240  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1>test.tsv
  241  for name in test.tsv; do echo "NAME : $name"; done
  242  rm test.txt
  243  rm test.tsv
  244  ls
  245  cd TEST
  246  ls
  247  vi name.txt
  248  rm test.txt
  249  cd ..
  250  for i in {0..3}; do echo "Number : $i"; done
  251  ls
  252  cd TEST
  253  ls
  254  for i in {1...1000}; do na = sed -n '{$i}p' TEST/name.txt; grep -n "na" amazon_reviews_us_Books_v1_02.tsv | cut –f13,14 > CUSTOMERS/na.txt; done
  255  cd ..
  256  for i in {1...1000}; do na = sed -n '{$i}p' TEST/name.txt; grep -n "na" amazon_reviews_us_Books_v1_02.tsv | cut –f13,14 > CUSTOMERS/na.txt; done
  257  for name in [TEST/name.txt]; do echo "NAME : $name"; done
  258  list = TEST/name.txt
  259  for i in $(seq 3); do    echo $i;    sleep 2 & done
  260  for i in $(seq 3); do    echo $i;    sleep 2 &; done
  261  for i in $(seq 3); do sleep 2; done
  262  for i in $(seq 3); do sleep 2& done
  263  ls
  264  for a in 'seq -w TEST/name.txt'; do grep -n "$a" amazon_reviews_us_Books_v1_02.tsv | cut –f13,14>TEST/$a; done
  265  for a in 'seq -w TEST/name.txt'; do grep -n "$a" amazon_reviews_us_Books_v1_02.tsv | cut –f13,14>TEST/$a.txt; done
  266  for i in 'seq -w TEST/name.txt'; do echo "NAME : $i"; done
  267  for a in 'seq -w amazon_reviews_us_Books_v1_02.tsv'; do echo "NAME : $a"; done
  268  for a in 'seq -w 100'; do echo "NAME : $a"; done
  269  for a in 'seq -w 100'; do echo $a; done
  270  for a in 'seq -w 100'; do $a; done
  271  for a in 'seq -w amazon_reviews_us_Books_v1_02.tsv'; do echo $a; done
  272  for a in 'seq -w TEST/name.txt'; do $a; done
  273  ls
  274  cd TEST
  275  ls
  276  cd ..
  277  mv TEST/name.txt CS131/name.txt
  278  cp TEST/name.txt CS131/name.txt
  279  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1>test.txt
  280  for name in seq -s " " 1 1000 test.txt; do $name; done
  281  ls
  282  for name in $(cat test.txt); do $name; done
  283  for name in $(cat test.txt); do echo name : $name; done
  284  cut -f2 test.txt
  285  cut -f1 test.txt
  286  cut -f3 test.txt
  287  head test.txt
  288  head test.txt|cut -f2
  289  head test.txt|cut -d" " -f2
  290  head test.txt|cut -d -f2
  291  head test.txt|cut -d -f1
  292  head test.txt|cut -d
  293  vi test.txt
  294  head test.txt
  295  cut -f3 test.txt
  296  cut -f4 test.txt
  297  cut -f5 test.txt
  298  cut -f0 test.txt
  299  cut -f1 test.txt
  300  awk '{print $1}' test.txt
  301  [출처] [리눅스 :: Bash 쉘 프로그래밍] awk :: 파일 출력하기|작성자 PN
  302  awk '{print $1}' test.txt
  303  awk '{print $2}' test.txt
  304  tail test.txt
  305  awk '{print $2}' test.txt > test.txt
  306  for name in $(cat test.txt); do grep -n "$name" amazon_reviews_us_Books_v1_02.tsv | cut –f13,14>TEST/$name.txt; done
  307  cd TEST
  308  ls
  309  cat name.txt
  310  cd ..
  311  ls
  312  for name in $(cat test.txt); do grep -n "$name" amazon_reviews_us_Books_v1_02.tsv;  done
  313  for name in $(cat test.txt); do echo name : $name; done
  314  for name in $(cat test.txt); echo "name : $name"
  315  for name in $(cat test.txt); do name : $name; done
  316  for name in $(cat test.txt); do echo name : $name; done
  317  heat test.txt
  318  head test.txt
  319  ls
  320  vi test.txt
  321  rm rest.txt
  322  rm test.txt
  323  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1>test.txt
  324  awk '{print $2}' test.txt > test.txt
  325  for name in $(cat test.txt); do echo name : $name; done
  326  head test.txt
  327  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1>test.txt
  328  tail test.txt
  329  awk '{print $2}' test.txt >> test.txt
  330  tail test.txt
  331  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|cut -f1|awk '{print $2}'
  332  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|awk '{print $2}'> test.txt
  333  tail test.txt
  334  for name in $(cat test.txt); do echo name : $name; done
  335  for name in $(cat test.txt); do grep -n "{$name}" amazon_reviews_us_Books_v1_02.tsv | cut –f13,14>TEST/'{$name}'.txt; done
  336  for name in $(cat test.txt); do grep -n "{$name}" amazon_reviews_us_Books_v1_02.tsv | cut –f13 >TEST/'{$name}'.txt; done
  337  for name in $(cat test.txt); do grep -n "{$name}" amazon_reviews_us_Books_v1_02.tsv | awk '{print $13}' >TEST/'{$name}'.txt; done
  338  cd TEST
  339  ls
  340  head '{$name}.txt'
  341  vi '{$name}.txt'
  342  head name.txt
  343  ls
  344  cd ..
  345  for name in $(cat test.txt); do grep -n "{$name}" amazon_reviews_us_Books_v1_02.tsv | awk '{print $13}' >TEST/{$name}.txt; done
  346  cd TEST
  347  ls
  348  head {50378566}.txt
  349  cd ..
  350  head test.txt
  351  grep -n "52432457" amazon_reviews_us_Books_v1_02.tsv | awk '{print $13}'
  352  grep -n "52432457" amazon_reviews_us_Books_v1_02.tsv | cut -f13
  353  grep -n "52432457" amazon_reviews_us_Books_v1_02.tsv | cut -f13,14
  354  for name in $(cat test.txt); do grep -n "{$name}" amazon_reviews_us_Books_v1_02.tsv | cut -f13 >TEST/{$name}.txt; done
  355  tmux attach -t homework
  356  ls
  357  cut -f2,3 amazon_reviews_us_Books_v1_02.tsv | sort -k1| uniq -w8 -c|sort -n|tail -1000|awk '{print $2}'> 1000cus.txt
  358  for name in $(cat 1000cus.txt); do grep -n "$name" amazon_reviews_us_Books_v1_02.tsv | cut -f13 >CUSTOMERS/$name.txt; done
  359  cd CUSTOMERS
  360  ls
  361  head 50142550.txt
  362  tmux new-session -s homework
  363  cd CS131
  364  ls
  365  for name in $(cat test.txt); do grep -n "$name" amazon_reviews_us_Books_v1_02.tsv | cut -f13 >TEST/{$name}.txt; done
  366  cd TEST
  367  ls
  368  head {49390985}.txt
  369  cd ..
  370  rm -rf TEST
  371  mkdir TEST
  372  ls
  373  history
  374  for name in $(cat test.txt); do grep -n "$name" amazon_reviews_us_Books_v1_02.tsv | cut -f13 >TEST/$name.txt; done
  375  cd TEST
  376  ls
  377  cd ..
  378  cd TEST
  379  head 50142550.txt
  380  cd ..
  381  rm -rf TEST
  382  rm -rf CUSTOMERS
  383  ls
  384  mkdir CUSTOMERS
  385  ls
  386  rm test.txt
  387  ls
  388  script ws5.txt
  389  vi ws5.txt
  390  git init
  391  git branch
  392  git checkout -b ws5
  393  history>cmdslog
  394  git add ws5.txt
  395  git add cmds.log
  396  git commit -m "ws5"
  397  git remote https://github.com/hyeyeonIm/CS131.git
  398  git push -u origin ws5
  399  ls
  400  history > cmds.log
  401  tail cmds.log
  402  git add cmds.log
  403  git commit -m "ws5"
  404  git push -u origin ws5
  405  git status
  406  git add cmds.log
  407  git push -u origin ws5
  408  cd CS131
  409  ls
  410  date
  411  timedatectl set-ntp 0
  412  timedatectl set-ntp false
  413  date
  414  date '+%Y-%m-%d'
  415  cd PRODUCTS
  416  ls
  417  cd ..
  418  cd CS131
  419  head amazon_reviews_us_Books_v1_02.tsv
  420  grep -n "047194128X" amazon_reviews_us_Books_v1_02.tsv | cut –f8
  421  grep -n "047194128X" amazon_reviews_us_Books_v1_02.tsv | cut -f8
  422  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f8
  423  grep -n "0870210092" amazon_reviews_us_Books_v1_02.tsv | cut -f8
  424  grep -n "0870210092" amazon_reviews_us_Books_v1_02.tsv
  425  cd PRODUCTS
  426  ls
  427  vi 047194128X.txt
  428  vi 0870210092.txt
  429  cd ..
  430  vi test2.txt
  431  grep -n "047194128X" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> test2.txt
  432  head test2.txt
  433  rm test2.txt
  434  ls
  435  cd ~/PRODUCTS
  436  ls
  437  cd PRODUCTS
  438  for i in 'ls *txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i   );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  |sort -n -r
  439  ls *txt
  440  for i in 'ls *txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  |sort -n -r
  441  for i in 'ls *txt'; do count = 0; total=0; for i in $(awk'{print $1}' $i); do total=$(echo $total+$i|bc); ((count++)); done; echo "scale=2"; echo "$total/$count"|bc; done
  442  tmux attach -t homework
  443  date "+%Y-%m-%d %I:%M:%S %p"
  444  cd PRODUCTS
  445  ls
  446  cp PRODUCTS/047194128X.txt PRODUCTS/047194128X.20221018_080735.txt
  447  cp 047194128X.txt 047194128X.20221018_080735.txt
  448  cp 0521314925.txt 0521314925.20221018_080735.txt
  449  cp 0870210092.txt 0870210092.20221018_080735.txt
  450  cat 0870210092.20221018_080735.txt
  451  cd ..
  452  grep -n "047194128X" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> PRODUCTS/047194128X.20221018_080735.txt
  453  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> PRODUCTS/0521314925.20221018_080735.txt
  454  grep -n "0870210092" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> PRODUCTS/0870210092.20221018_080735.txt
  455  ln -s PRODUCTS/047194128X.20221018_080735.txt PRODUCTS/047194128X.LATEST.txt
  456  ln -s PRODUCTS/0521314925.20221018_080735.txt PRODUCTS/0521314925.LATEST.txt
  457  ln -s PRODUCTS/0870210092.20221018_080735.txt PRODUCTS/0870210092.LATEST.txt
  458  crontab -e
  459  crontab -l
  460  cd PRODUCTS
  461  for i in '047194128X.LATEST.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  
  462  ls
  463  for i in '047194128X.LATEST.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  464  for i in '0521314925.LATEST.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  465  for i in '0870210092.LATEST.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  466  cat 0870210092.LATEST.txt
  467  cat 0870210092.20221018_080735.txt
  468  for i in '047194128X.20221018_080735.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  
  469  for i in '0521314925.20221018_080735.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  
  470  for i in '0870210092.20221018_080735.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  471  tmux new-session -s homework
  472  cd CS131
  473  ls
  474  date
  475  date "+%Y-%m-%d %I:%M:%S %p"
  476  cd PRODUCTS
  477  ls
  478  for i in '0870210092.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  |sort -n -r
  479  cat 0870210092.txt
  480  cd ..
  481  cd PRODUCTS
  482  ls
  483  cd ..
  484  ls
  485  script ws6.txt
  486  vi ws6.txt
  487  vi ws6.tct
  488  rm ws6.tct
  489  vi ws6.txt
  490  cd CS131
  491  ls
  492  rm ws6.txt
  493  cd PRODUCTS
  494  ls
  495  cat 047194128X.txt
  496  rm 047194128X.20221018_080735.txt
  497  rm 0521314925.20221018_080735.txt
  498  rm 0870210092.20221018_080735.txt
  499  rm 047194128X.LATEST.txt
  500  rm 0521314925.LATEST.txt
  501  rm 0870210092.LATEST.txt
  502  ls
  503  cd ..
  504  crontab -l
  505  crontab -r
  506  crontab -l
  507  tmux attach -t homework
  508  date "+%Y-%m-%d %I:%M:%S %p"
  509  cd PRODUCTS
  510  ls
  511  cd ..
  512  cp PRODUCTS/047194128X.txt PRODUCTS/047194128X.20221019_011258.txt
  513  cp PRODUCTS/0521314925.txt PRODUCTS/0521314925.20221019_011258.txt
  514  cp PRODUCTS/0870210092.txt PRODUCTS/0870210092.20221019_011258.txt
  515  grep -n "047194128X" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> PRODUCTS/047194128X.20221019_011258.txt
  516  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> PRODUCTS/0521314925.20221019_011258.txt
  517  grep -n "0870210092" amazon_reviews_us_Books_v1_02.tsv | cut -f8 >> PRODUCTS/0870210092.20221019_011258.txt
  518  ln -s PRODUCTS/047194128X.20221019_011258.txt PRODUCTS/047194128X.LATEST.txt
  519  ln -s PRODUCTS/0521314925.20221019_011258.txt PRODUCTS/0521314925.LATEST.txt
  520  ln -s PRODUCTS/0870210092.20221019_011258.txt PRODUCTS/0870210092.LATEST.txt
  521  crontab -e
  522  crontab -l
  523  for i in '047194128X.20221019_011258.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  
  524  cd PRODUCTS
  525  for i in '047194128X.20221019_011258.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  
  526  for i in '0521314925.20221019_011258.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done  
  527  for i in '0870210092.20221019_011258.txt' ; do count=0; total=0; for i in $( awk '{ print $1; }'  $i );do total=$(echo $total+$i | bc ); ((count++)); done; echo "scale=2; $total / $count" | bc ; done
  528  tmux new-session -s homework
  529  cd CS131
  530  script ws6.txt
  531  vi ws6.txt
  532  cat ws6.txt
  533  1;0c
  534  history > cmds.log
  535  cat cmds.log
  536  git init
  537  git branch
  538  git checkout -b ws6
  539  git branch
  540  git add ws6.txt
  541  git add cmds.log
  542  git commit -m "ws6"
  543  git remote https://github.com/hyeyeonIm/CS131.git
  544  git push -u origin ws6
  545  cd CS131
  546  ls
  547  cut -f1,5 downloaded_tweets_extend_nolf2.tsv downloaded_tweets_extend_nolf2.tsv|fgrep -i "retweeted"|sort -k1|uniq -w18  -c|sort –n|tail -10
  548  tmux attach -t homework
  549  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed 's/ type=retweeted.//g' > retweets.txt
  550  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | awk -F'\t' '{print $2}' > users_retweeted.txt
  551  sort users_retweeted.txt | uniq -c | sort -n | tail -10
  552  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv |awk -F'\t' '{print $2,$1}' > a4_retweets.csv
  553  cat users_retweeted.txt | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }' > a4_data.csv
  554  /etc/gnuplot-5.4.4/src/gnuplot
  555  grep "741190491195248642" downloaded_tweets_extend_original_nolf2.tsv|cut -f4|sort|uniq -c|sort -n|tail -30 > a4_hashtag.txt
  556  head a2_hashtag.txt
  557  diff a4_hashtag.txt a2_hashtag.txt
  558  head a4_retweets.csv
  559  cd CS131
  560  cp /home/test/A1/downloaded_tweets_extend_nolf2.tsv $HOME
  561  cp /home/test/A1/downloaded_tweets_extend_original_nolf2.tsv $HOME
  562  ls
  563  head downloaded_tweets_extend_nolf2.tsv
  564  cut -f1,5 downloaded_tweets_extend_nolf2.tsv downloaded_tweets_extend_nolf2.tsv|fgrep -i "retweeted"|sort -k1|uniq -w18  -c|sort –n|tail –10
  565  cut -f1,5 downloaded_tweets_extend_nolf2.tsv downloaded_tweets_extend_nolf2.tsv|fgrep -i "retweeted"|sort -k1|uniq -w18  -c|sort –n|tail -10
  566  cut -f1,5 downloaded_tweets_extend_nolf2.tsv downloaded_tweets_extend_nolf2.tsv|fgrep -i "retweeted"|sort -k1|uniq -w18  -c|sort -n|tail -10
  567  p retweeted downloaded_tweets_extend_nolf2.tsv|awk -F'\t' '{print $5}'|sed 's/^.* id=//g'|sed='s/ type=retweeted.//g'
  568  grep retweeted downloaded_tweets_extend_nolf2.tsv|awk -F'\t' '{print $5}'|sed 's/^.* id=//g'|sed='s/ type=retweeted.//g'
  569  grep retweeted downloaded_tweets_extend_nolf2.tsv|awk -F'\t' '{print $5}'|sed 's/^.* id=//g'|sed='s/ type=retweetd.//g'
  570  grep replied downloaded_tweets_extend_nolf2.tsv|awk -F'\t' '{print $5}' | less
  571  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}'
  572  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g'
  573  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed='s/ type=retweeted]//g'
  574  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed='s/ type=g'
  575  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed='s/type=retweeted.//g'
  576  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed='s/ type=retweeted]//g'
  577  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed='s/^.* type=//g'
  578  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g'
  579  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed='s/^.* type=retweeted.//g'
  580  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed 's/ type=retweeted.//g'
  581  ls
  582  cat '_extend_nolf2.tsv | awk -F'\''t'\'' '\''{print $5}'\'''
  583  rm '_extend_nolf2.tsv | awk -F'\''t'\'' '\''{print $5}'\'''
  584  ls
  585  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed 's/ type=retweeted.//g' > retweets.txt
  586  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | awk -F'\t' '{print $2}' > users_retweeted.txt
  587  sort users_retweeted.txt | uniq -c | sort -n | tail -10
  588  cat retweets.txt
  589  grep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv
  590  grep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv|head
  591  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | awk -F'\t' '{print $2}'|head
  592  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | cut -f1,2|head
  593  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | cut -f2,1
  594  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | cut -f1,2|head
  595  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | cut -f2,1|head
  596  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv |awk -F'\t' '{print $2,1}'
  597  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv |awk -F'\t' '{print $2,$1}'|head
  598  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | cut -f1,2|head
  599  head a2_hashtag.txt
  600  ls
  601  rm retweets.txt
  602  rm users_retweeted.txt
  603  ls
  604  gephi
  605  script a4.txt
  606  tmux new-session -s homework
  607  vi a4.txt
  608  ls
  609  cat a4.txt
  610  cd CS131
  611  ls
  612  rm a4.txt
  613  sort a4_retweets.csv|head
  614  head -n 20 a4_retweets.csv
  615  cut -f1 457060718 1004656199885836288
  616  140496030 1017456403961835520
  617  202615056 1023111834587607041
  618  202615056 1026437890731999232
  619  288417339 1026716985143508992
  620  80797203 1027189486466330624
  621  1223514530 1036740863551053824
  622  74468291 1039512558946811904
  623  741190491195248642 1040192907855187968
  624  126646669 1040337381356974081
  625  2447612839 1043987153926201345
  626  16050065 1045330832917839873
  627  16050065 1045333151877234688
  628  16050065 1045373050751860737
  629  16050065 1045375787514249217
  630  16050065 1045377009205960704
  631  16050065 1045377571376967680
  632  16050065 1045378154766848000
  633  16050065 1045378819182358528
  634  tmux attach -t homework
  635  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{print $5}' | sed 's/^.* id=//g' | sed 's/ type=retweeted.//g' > retweets.txt
  636  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv | awk -F'\t' '{print $2}' > users_retweeted.txt
  637  sort users_retweeted.txt | uniq -c | sort -n | tail -10
  638  fgrep -f retweets.txt downloaded_tweets_extend_original_nolf2.tsv |awk -F'\t' '{print $2,$1}' > a4_retweets.csv
  639  cat users_retweeted.txt | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }' > a4_data.csv
  640  /etc/gnuplot-5.4.4/src/gnuplot
  641  grep "741190491195248642" downloaded_tweets_extend_original_nolf2.tsv|cut -f4|sort|uniq -c|sort -n|tail -30 > a4_hashtag.txt
  642  head a2_hashtag.txt
  643  diff a4_hashtag.txt a2_hashtag.txt
  644  tmux new-session -s homework
  645  head a4.txt
  646  cd CS131
  647  script a4.txt
  648  head a4.txt
  649  cd CS131
  650  vi a4.txt
  651  cat a4.txt
  652  1;0c
  653  head a4.txt
  654  1;0c
  655  cd CS131
  656  git init
  657  git branch
  658  git checkout -b a4
  659  git branch
  660  git add a4.txt
  661  git commit -m "a4"
  662  git push -u origin a4
  663  ls
  664  pwd
  665  scp hyeyeon@172.31.197.164:/home/hyeyeon/CS131/a4_retweets.csv C:\cs131
  666  scp -P hyeyeon@172.31.197.164:/home/hyeyeon/CS131/a4_retweets.csv C:\cs131
  667  scp a4_retweets.csv hyeyeon@172.31.197.164:/home/hyeyeon/CS131 C:\cs131
  668  tar -zcvf a4.tar.gz a4_retweets.csv
  669  ls
  670  scp -P 32222 hyeyeon@172.31.197.164:~/a4.tar.gz C:
  671  rm a4.tar.gz
  672  ls
  673  cat a4_retweets.csv>try.txt
  674  ls
  675  vi try.txt
  676  cd CS131
  677  ls
  678  vi try.txt
  679  cd CS131
  680  ls -lrt
  681  vncserver -list
  682  cd CS131
  683  ls
  684  wget -q --show-progress 
  685  wget -q --show-progress https://github.com/gephi/gephi/releases/download/v0.9.2/gephi-0.9.2-linux.tar.gz
  686  tar xzf gephi-0.9.2-linux.tar.gz
  687  ./gephi-0.9.2/bin/gephi
  688  sudo add-apt-repository ppa:openjdk-r/ppa
  689  ls
  690  ls -lr
  691  cd CS131
  692  cd CS131
  693  ls -tr
  694  ls -lr
  695  cd CS131
  696  ls
  697  ls -atlr
  698  cd PRODUCTS
  699  ls -atlr
  700  cat 047194128X.20221019_011258.txt
  701  cd ..
  702  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv
  703  head amazon_reviews_us_Books_v1_02.tsv
  704  cut -f4,14 amazon_reviews_us_Books_v1_02.tsv | head
  705  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14
  706  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | awk '{print$4,$14}'
  707  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv
  708  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed '/^,*$/d' | sed '/^.*$/d' | sed '/^;*$/d'
  709  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f14 | sed '/^,*$/d' | sed '/^.*$/d' | sed '/^;*$/d'
  710  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,1
  711  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f14 | sed '/^,*$/d'
  712  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed '/^,*$//g' 
  713  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/^.*$//g'
  714  cd CS131
  715  ls -atlr
  716  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,1
  717  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14
  718  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/.$//g'
  719  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/.$/d'
  720  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed's/\.//g'
  721  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\.//g'
  722  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\(//g' | sed 's/\)//g' | sed 's/\-//g' | sed 's/\&//g'
  723  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\-//g' | sed 's/\&//g'
  724  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\<.../>//g' 
  725  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,.;-&//g'
  726  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/[,.;-&]//g'
  727  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -r 's/\(.,;-&)//g'
  728  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -r 's/\(.,;-&\)//g'
  729  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -r 's/\.,;-&//g'
  730  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -r 's/\[.,;-&]//g'
  731  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g'
  732  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs//g'
  733  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -i 's/imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs//g' 
  734  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -i 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g' 
  735  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g' 
  736  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g'
  737   | sed 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g' 
  738  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g' 
  739  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed '/^$/d'
  740  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -e 's/^ *//g' -e 's/ *$//g'
  741  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed -r 's/\s+//g'
  742  cd PRODUCTS
  743  ls -atlr
  744  cd ..
  745  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14
  746  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14 | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed -r 's/\s+//g'
  747  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f4,14  | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed -r 's/\s+//g' | sed 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g' 
  748  grep -n "0521314925" amazon_reviews_us_Books_v1_02.tsv | cut -f14  | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed -r 's/\s+//g' | sed 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g' > review_body.txt
  749  cat review_body.txt
  750  history > cmds.log
  751  tail cmds.log
  752  tmux new-session -s homework
  753  cd CS131
  754  ls
  755  script ws7.txt
  756  vi ws7.txt
  757  git init
  758  git branch
  759  git checkout -b ws7
  760  git branch
  761  git add ws7.txt
  762  git commit -m "ws7"
  763  git remote https://github.com/hyeyeonIm/CS131.git
  764  git push -u origin ws7
  765  git init
  766  git add cmds.log
  767  git push -u origin ws7
  768  git status
  769  git commit -m "ws7"
  770  git push -u origin ws7
  771  ls
  772  git add remote origin https://github.com/hyeyeonIm/CS131.git
  773  git remote origin https://github.com/hyeyeonIm/CS131.git
  774  git add remote https://github.com/hyeyeonIm/CS131.git
  775  cd CS131
  776  ls -atlr
  777  head amazon_reviews_us_Books_v1_02.tsv
  778  head amazon_reviews_us_Books_v1_02.tsv | grep "veritied"
  779  cut -f12 amazon_reviews_us_Books_v1_02.tsv | head
  780  awk '{print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  781  awk -F 'tap' '{print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  782  awk -F 't' '{print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  783  awk '{print $11}' amazon_reviews_us_Books_v1_02.tsv | head
  784  awk '{print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  785  cut -f12 amazon_reviews_us_Books_v1_02.tsv 
  786  awk '{print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  787  cut -f12 amazon_reviews_us_Books_v1_02.tsv |head
  788  head amazon_reviews_us_Books_v1_02.tsv 
  789  awk -F/ '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  790  awk -F\ '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  791  awk -F/t '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  792  cut -f12,14 amazon_reviews_us_Books_v1_02.tsv | awk '{print $2}' | head
  793  cut -f12,14 amazon_reviews_us_Books_v1_02.tsv | cut -f2  | head
  794  awk -F'/t' '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  795  awk -F'/' '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  796  awk -F'[ :\t]' '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  797  awk -F\t '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  798  awk -F't' '{print $12}' amazon_reviews_us_Books_v1_02.tsv |head
  799  awk -F'tN/tY/t' amazon_reviews_us_Books_v1_02.tsv\head
  800  grep -P 'tN/tY/t' amazon_reviews_us_Books_v1_02.tsv | head
  801  awk '{print $0}' amazon_reviews_us_Books_v1_02.tsv |head
  802  awk '{print $1}' amazon_reviews_us_Books_v1_02.tsv |head
  803  awk '{print $2}' amazon_reviews_us_Books_v1_02.tsv |head
  804  awk '{print $3}' amazon_reviews_us_Books_v1_02.tsv |head
  805  awk '{print $4}' amazon_reviews_us_Books_v1_02.tsv |head
  806  awk '{print $5}' amazon_reviews_us_Books_v1_02.tsv |head
  807  awk '{print $6}' amazon_reviews_us_Books_v1_02.tsv |head
  808  awk '{print $7}' amazon_reviews_us_Books_v1_02.tsv |head
  809  awk '{print $8}' amazon_reviews_us_Books_v1_02.tsv |head
  810  awk '{print $9}' amazon_reviews_us_Books_v1_02.tsv |head
  811  cut -f7 amazon_reviews_us_Books_v1_02.tsv |head
  812  awk -F '[\t]' '{print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  813  awk -F '[\t]' '{print $12$14}' amazon_reviews_us_Books_v1_02.tsv | head
  814  awk -F '[\t]' '{print $12,$14}' amazon_reviews_us_Books_v1_02.tsv | head
  815  awk -F '[\t]' '{print $1,$2}' amazon_reviews_us_Books_v1_02.tsv | head
  816  awk -F '[\t]' '{print $1$2}' amazon_reviews_us_Books_v1_02.tsv | head
  817  awk -F '[\t]' '{print $1,$2}' amazon_reviews_us_Books_v1_02.tsv | head
  818  awk -F '[\t]' '{print $12='Y'}' amazon_reviews_us_Books_v1_02.tsv
  819  awk -F '[\t]' '{print $12='Y'}' amazon_reviews_us_Books_v1_02.tsv | awk -F '[\t]' '{print $12}' |head
  820  awk -F '[\t]' '{print $12="Y"}' amazon_reviews_us_Books_v1_02.tsv | awk -F '[\t]' '{print $12}' |head
  821  awk -F '[\t]' '{print $12=="Y"}' amazon_reviews_us_Books_v1_02.tsv | awk -F '[\t]' '{print $12}' |head
  822  awk -F '[\t]' '{if($12=="Y")print $12}' amazon_reviews_us_Books_v1_02.tsv | head
  823  cd CS131
  824  ls -atlr
  825  ls
  826  awk -F '[\t]' '{if($12=="N")print $14}' amazon_reviews_us_Books_v1_02.tsv|head
  827  awk -F '[\t]' '{if($12=="N")print $12}' amazon_reviews_us_Books_v1_02.tsv|head
  828  awk -F '[\t]' '{if($12=="Y")print $14}' amazon_reviews_us_Books_v1_02.tsv > verified.txt
  829  grep -w verified.txt| sort -n | uniq -c | sort -n | tail
  830  grep -w verified.txt| head
  831  verified.txt | uniq -c
  832  cat verified.txt | wc -w | uniq -c
  833  cat verified.txt | wc -w
  834  cat verified.txt | wc -w | uniq -c
  835  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed 's/[imemymyselfweouroursourselvesyouyouryoursyourselfyourselveshehimhishimselfsheherhersherselfititsitselftheythemtheirtheirs]//g'
  836  gn n' aa a na  S Capn' ban ang g  ndd  c a b ndca  a dcn a  <b /><b />Capn k an  an a  p and dc  dnc ad png  H pnan   p  pa cap and pa c pnd candd and a On    
  837  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed 's/[i,me,my,myself,we,our,ours]//g'
  838  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed 's/[I,me,My,my,myself,We,we,our,ours,ourselves,you,your,yours,yourself,yourselves,he,him,his,himself,she,her,hers,herself,It,its,itself,They,them,their,theirs]//g'
  839  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\-//g' | sed 's/\&//g' | sed 's/[the, of, and, to, in, a, that, this, is, for]//g'
  840  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\\//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/[the, of, and, to, in, a, that, this, is, for]//g'
  841  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\\\//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/[the, of, and, to, in, a, that, this, is, for]//g'
  842  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/[the, of, and, to, in, a, that, this, is, for]//g'
  843  head verified.txt | sed 's/\[<>]//g' 
  844  head verified.txt | sed 's/\>//g' 
  845  head verified.txt | sed 's/<[^>]*>//g' 
  846  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/[the, of, and, to, in, a, that, this, is, for]//g'
  847  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/[the,of,and,to,in,a,that,this,is,for]//g'
  848  head verified.txt | sed 's/<[^>]*>//g'
  849  grep [a-zA-Z] verified.txt | sort -n | uniq -c | sort -n | tail
  850  head verified.txt | grep [a-zA-Z] | sort -n | uniq -c | sort -n | tail
  851  grep [a-zA-Z] verified.txt | sort -n | uniq -c | sort -n | tail
  852  grep [a-zA-Z] verified.txt
  853  grep [a-z] verified.txt | head
  854  grep [a-zA-Z] verified.txt | head
  855  grep [a-zA-Z] verified.txt | sort | head
  856  grep [a-zA-Z] verified.txt | sort | uniq -c | head
  857  ls
  858  rm verified.txt
  859  ls
  860  cd CS131
  861  ls -atlr
  862  awk -F '[\t]' '{print $12,$14}' amazon_reviews_us_Books_v1_02.tsv | head
  863  awk -F '[\t]' '{if($12=="Y")print $14}' amazon_reviews_us_Books_v1_02.tsv > verified.txt
  864  head verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' | sed 's/[the, of, and, to, in, a, that, this, is, for]//g'
  865  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/[the,of,and,to,in,a,that,this,is,for]//g'
  866  head -n 5 verified.txt | sed 's/<^>*>//g'
  867  head -n3 verified.txt | sed 's/<^>*>//g'
  868  head -n1 verified.txt | sed 's/<^>*>//g'
  869  head -n2 verified.txt | sed 's/<^>*>//g'
  870  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/[the,of,and,to,in,a,that,this,is,for]//g'
  871  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/the//g'
  872  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/the,to//g'
  873  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/[theto]//g'
  874  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/[the,to]//g'
  875  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g'
  876  head -n2 verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g'  
  877  head -n2 verified.txt 
  878  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -10
  879  head verified.txt > verified.txt 
  880  cat verified.txt 
  881  awk -F '[\t]' '{if($12=="Y")print $14}' amazon_reviews_us_Books_v1_02.tsv > verified.txt
  882  head verified.txt >> verified.txt 
  883  cat verified.txt 
  884  head -n10 verified.txt >> verified.txt 
  885  cat verified.txt 
  886  cat verified.txt | head -n10 >> verified.txt 
  887  vat verified.txt 
  888  cat verified.txt 
  889  cat verified.txt | tail -3
  890  cat verified.txt | tail -3 >> verified.txt 
  891  cat verified.txt 
  892  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g' >> verified.txt  
  893  cat verified.txt 
  894  cat verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g' >> verified.txt
  895  head verified.txt 
  896  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g' > testfile.txt
  897  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g' > fileof.txt
  898  pwd
  899  head verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g'
  900  vi testfile.txt
  901  cat testfile.txt
  902  ls -atlr
  903  rm gephi-0.9.2
  904  ls
  905  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -10
  906  cd CS131
  907  ls -atlr
  908  head -n5 verified.txt >> verified.txt
  909  head verified.txt
  910  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -10
  911  cat verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' >> verified.txt 
  912  cat verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g' >> verified.txt  
  913  cat verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g
  914  '
  915  cat verified.txt 
  916  head -n5 verified.txt >> verified.txt
  917  cat verified.txt
  918  awk "NR >= 1 %% NR <=10" amazon_reviews_us_Books_v1_02.tsv 
  919  awk "NR >= 1 &&  NR <=10" amazon_reviews_us_Books_v1_02.tsv 
  920  awk "NR >= 1 && NR <=100" amazon_reviews_us_Books_v1_02.tsv > amazon.tsv
  921  pwd
  922  cd ..
  923  pwd
  924  ls
  925  cd ..
  926  ls
  927  cd ..
  928  ls
  929  cd mnt
  930  ls
  931  cd scratch
  932  ls
  933  cd hyeyeon
  934  ls
  935  cd ..
  936  ls
  937  cd home
  938  ls
  939  cd hyeyeon
  940  cd CS131
  941  ls -atlr
  942  cp amazon_reviews_us_Books_v1_02.tsv /mnt/scratch
  943  cd ..
  944  ls
  945  cd mnt
  946  ls
  947  cd scratch
  948  ls
  949  cd hyeyeon
  950  wget    https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz
  951  ls
  952  cd CS131
  953  rm amazon_reviews_us_Books_v1_02.tsv.gz 
  954  ls
  955  mkdir CS131
  956  cd CS131
  957  ls
  958  wget    https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz
  959  head amazon_reviews_us_Books_v1_02.tsv.gz 
  960  xterm-256colorxterm-256colorxterm-256colorxterm-256colorxterm-256colorxterm-256colorxterm-256colorxterm-256colorxterm-256color
  961  tar -zxvf amazon_reviews_us_Books_v1_02.tsv.gz
  962  cp /home/hyeyeon/CS131/amazon_reviews_us_Books_v1_02.tsv /mnt/scratch/hyeyeon/CS131
  963  ls
  964  head amazon_reviews_us_Books_v1_02.tsv
  965  awk -F '[\t]' '{print $14}' amazonpwd
  966  cd ..
  967  ls
  968  cd mnt
  969  ls
  970  cs scratch
  971  cd scratch
  972  cd hyeyeon
  973  cd CS131
  974  ls
  975  rm verified.txt 
  976  ls -atlr
  977  cat amazon.tsv
  978  awk -F '[\t]' '{if($12=="Y")print $14}' amazon.tsv > verified.txt
  979  cat verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g'
  980  cat verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g'
  981  cat verified.txt | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' >> verified.txt 
  982  head verified.txt 
  983  cat verified.txt | sed 's/<[^>]*>//g'  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/for//g' >> verified.txt 
  984  cat verified.txt 
  985  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -10
  986  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -n
  987  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -20
  988  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -30
  989  head amazon.tsv
  990  head verified.txt 
  991  tr -c '[:alnum:]' '[\n*]' < verified.txt | sort | uniq -c | sort -nr | head  -50
  992  tmux attach -t homework
  993  awk -F '[\t]' '{print $14}' amazon_reviews_us_Books_v1_02.tsv | head
  994  awk "NR >= 1 && NR <=100" amazon_reviews_us_Books_v1_02.tsv > amazon.tsv
  995  awk -F '[\t]' '{print $12,$14}' amazon.tsv | head
  996  awk -F '[\t]' '{if($12=="Y")print $14}' amazon.tsv > verified.txt
  997  tmux new-session -s homework
  998  tmux attach -t homework
  999  awk -F '[\t]' '{print $14}' amazon_reviews_us_Books_v1_02.tsv | head
 1000  awk "NR >= 1 && NR <=100" amazon_reviews_us_Books_v1_02.tsv > amazon.tsv
 1001  awk -F '[\t]' '{print $12,$14}' amazon.tsv | head
 1002  awk -F '[\t]' '{if($12=="Y")print $14}' amazon.tsv > verified.txt
 1003  awk -F '[\t]' '{if($12=="N")print $14}' amazon.tsv > unverified.txt
 1004  sed 's/<[^>]*>//g' verified.txt  | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' > verified1.txt  
 1005  tr -c '[:alnum:]' '[\n*]' < verified1.txt | sort | uniq -c | sort -nr | head  -30
 1006  sed 's/<[^>]*>//g' unverified.txt | sed 's/to//g' | sed 's/the//g' | sed 's/of//g' | sed 's/and//g' | sed 's/you//g' | sed 's/he//g' | sed 's/It//g' | sed 's/I//g' | sed 's/be//g' | sed 's/or//g' | sed 's/The//g' | sed 's/in//g' | sed 's/a//g' | sed 's/that//g' | sed 's/this//g' | sed 's/is//g' | sed 's/it//g' | sed 's/not//g' | sed 's/for//g' | sed 's/\,//g' | sed 's/\.//g' | sed 's/\;//g' | sed 's/\[<>]//g' |sed 's/\-//g' | sed 's/\&//g' > unverified1.txt  
 1007  tr -c '[:alnum:]' '[\n*]' < unverified1.txt | sort | uniq -c | sort -nr | head  -30
 1008  history > cmds.log
